{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "successful-light",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Loan_ID  Gender  ApplicantIncome  CoapplicantIncome  LoanAmount   Area\n",
      "2   LP001005    Male           3000.0                0.0        66.0    NaN\n",
      "10  LP001024  Female           3200.0              700.0        70.0  urban\n",
      "7   LP001014  Female           3036.0             2504.0       158.0   semi\n",
      "1   LP001003    Male           4583.0                NaN       128.0   semi\n",
      "9   LP001020    Male          12841.0            10968.0       349.0   semi\n",
      "8   LP001018    Male           4006.0             1526.0       168.0  rural\n",
      "4   LP001008    Male              NaN                0.0       141.0  urban\n",
      "5   LP001011    Male           5417.0             4196.0       267.0   semi\n",
      "6   LP001013    Male           2333.0             1516.0         NaN  rural\n",
      "3   LP001006  Female           2583.0             2358.0       120.0   semi\n",
      "15  LP001032    Male           4950.0                0.0       125.0   semi\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------\n",
    "# Data processing template\n",
    "# --------------------------------------------------\n",
    "\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Read data from the csv file\n",
    "data_folder = \"C:\\\\Users\\\\elidmoore\\\\Documents\\Personal Documents\\\\Data Science 2021 Course\\\\004 - Data Preprocessing\\\\\"\n",
    "file_to_open = data_folder + \"loan_small.CSV\"\n",
    "df = open(file_to_open)\n",
    "dataset = pd.read_csv(df)\n",
    "\n",
    "# Access the data using iloc. \n",
    "# Example - Get first three rows from the second and third column\n",
    "subset = dataset.iloc[0:3, 1:3]\n",
    "\n",
    "# Access the data using column names\n",
    "# Get all rows of the column Gender and ApplicantIncome\n",
    "subsetN = dataset[['Gender', 'ApplicantIncome']]\n",
    "\n",
    "# Get first three rows of the columns Gender and ApplicantIncome\n",
    "subsetN = dataset[['Gender', 'ApplicantIncome']][0:3]\n",
    "\n",
    "\n",
    "# display a small set of data for quick check on a large data\n",
    "dataset.head(10)\n",
    "\n",
    "# Get the Shape of the dataframe (Row x Columns)\n",
    "dataset.shape\n",
    "\n",
    "# Get column names of the dataframe\n",
    "dataset.columns\n",
    "\n",
    "# Store column names of the dataframe in a list\n",
    "column_list = dataset.columns.to_list()\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Handling missing values\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "# Find out columns with missing values with their count\n",
    "dataset.isnull().sum(axis=0)\n",
    "\n",
    "# Drop all the rows with missing values\n",
    "dataset_clean = dataset.dropna()\n",
    "\n",
    "# Drop all the rows with missing values of a particular column \n",
    "dataset_clean = dataset.dropna(subset=[\"Loan_Status\"])\n",
    "\n",
    "\n",
    "# Replace missing categorical values using column names\n",
    "dt = dataset.copy()\n",
    "cols = ['Gender', 'Area', 'Loan_Status']\n",
    "\n",
    "# fillna for filling NaN values\n",
    "dt[cols] = dt[cols].fillna(dt.mode().iloc[0])\n",
    "dt.isnull().sum(axis=0)\n",
    "\n",
    "# Replace missing numerical values using column names\n",
    "cols2 = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount']\n",
    "\n",
    "# fillna for filling NaN values\n",
    "dt[cols2] = dt[cols2].fillna(dt.mean())\n",
    "dt.isnull().sum(axis=0)\n",
    "\n",
    "#\n",
    "# ---------------------------------------------------------\n",
    "# label encoding - Convert Categorical to Numerical values\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# Get datatypes of all the columns of the dataframe\n",
    "dt.dtypes\n",
    "\n",
    "# Convert string/object column types to categorical \n",
    "dt[cols] = dt[cols].astype('category')\n",
    "\n",
    "# Convert string to numerical codes\n",
    "for columns in cols:\n",
    "    dt[columns] = dt[columns].cat.codes\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Hot encoding or Dummy Variable Creation\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# Drop a column using column name\n",
    "df2 = dataset.drop(['Loan_ID'], axis=1)\n",
    "\n",
    "# using get_dummies function of Pandas\n",
    "df2 = pd.get_dummies(df2)\n",
    "\n",
    "# Avoid dummy variable trap using drop_first\n",
    "df3 = dataset.drop(['Loan_ID'], axis=1)\n",
    "df3 = pd.get_dummies(df3, drop_first=True)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Data Normalization using Standardscaler and MinMax \n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# extract data to scale\n",
    "data_to_scale = dataset_clean.iloc[:, 2:5]\n",
    "\n",
    "# Import the StandardScaler class\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create an object of the class StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and Transform the data for normalization\n",
    "ss_scaler = scaler.fit_transform(data_to_scale)\n",
    "\n",
    "# MinMax Normalization of the data\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "# Fit and Transform the data for MinMax normalization\n",
    "mm_scaler = minmax_scale(data_to_scale)\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Split the Data by rows and columns\n",
    "# ----------------------------------------------------------\n",
    "df = dataset.copy()\n",
    "\n",
    "# Split by column for X(independent) and Y(dependent) variables\n",
    "X = df.iloc[:, :-1]\n",
    "Y = df.iloc[:,  -1]\n",
    "\n",
    "# Split by rows for training and test datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test =      \\\n",
    "train_test_split(X, Y, test_size=0.3, random_state=1234)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
