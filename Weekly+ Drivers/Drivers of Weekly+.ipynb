{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c92257b-7b97-4a49-9bce-e2d5fc605637",
   "metadata": {},
   "source": [
    "# Drivers of Weekly+\n",
    "The purpose of this notebook is to identify the best leading indicator of Weekly+, then determine the behavioral, attitudinal, and perception drivers of Weekly+. It does this with live connections to SQL (where BEACH raw data is stored) and connections to the BEACH data model (the Power BI Semantic model). It then uses ChatGPT to summarize the results for ease of understanding by non-technical users.\n",
    "\n",
    "Step 1: Initialize connections and load packages\n",
    "\n",
    "Step 2: Identify which measure we should use as a leading indicator\n",
    "\n",
    "Step 3: Get data from SQL\n",
    "\n",
    "Step 4: Perform models to measure drivers\n",
    "\n",
    "Step 5: Summarize results for non-technical users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4de672-f239-4b95-a21a-f7fa4ba357e7",
   "metadata": {},
   "source": [
    "## Initialization of the Model\n",
    "Load Packages and Decide What to Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56694a5-5d82-4f5c-9d6b-19664ce9bb37",
   "metadata": {},
   "source": [
    "#### Load Packages to be used by this program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76e843ab-d0e6-42d3-b703-a0b9eb38af4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pyadomd import Pyadomd\n",
    "import pyodbc\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import difflib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "from sklearn.inspection import partial_dependence\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.under_sampling import RandomUnderSampler  # Import the undersampler\n",
    "import statsmodels.api as sm\n",
    "from sqlalchemy import create_engine\n",
    "import urllib.request\n",
    "import json\n",
    "from pptx import Presentation\n",
    "from pptx.util import Pt\n",
    "from pptx.enum.text import PP_ALIGN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94340fd-5a9b-4647-a155-96f0480a0a2d",
   "metadata": {},
   "source": [
    "#### Decide which country and brand you want to analyze drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9d865ab-e69c-4793-a737-1419ef8edb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_id = 'USA'\n",
    "brand_id = 'br_0201'\n",
    "drink_type = \"SSD Regular\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e621f263-3012-48b6-9ce4-e257cba583a6",
   "metadata": {},
   "source": [
    "#### Set Power BI Connection Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caf7cc92-c22e-42e5-ab47-5bda82969aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connection details\n",
    "dataset = 'BEACH'\n",
    "port_number = 'powerbi://api.powerbi.com/v1.0/myorg/SIMON BEACH'\n",
    "user_id = 'elimoore@coca-cola.com'\n",
    "password = os.environ.get(\"KO_PASSWORD\")\n",
    "pbi_connection_string = f'Provider=MSOLAP;Data Source={port_number};Catalog={dataset};User ID={user_id};Password={password};'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b347ad-9459-4f64-b7b2-97f8249b3f28",
   "metadata": {},
   "source": [
    "#### Load OpenAI Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "225cc040-ed4f-4a5c-b420-adbc87762e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI client\n",
    "#api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "deployment = 'gpt-4'\n",
    "apiversion = '2024-06-01'\n",
    "api_key = os.environ.get(\"KO_GPT_API\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2f48cd-934c-4baf-b32e-7c1d5d642b02",
   "metadata": {},
   "source": [
    "#### Set SQL Server Connection Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18deaf92-25d3-44de-8701-91709d9d7d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connection information\n",
    "server = 'syn-tccc-blc-use2-prod-01-ondemand.sql.azuresynapse.net'\n",
    "database = 'beach_db'\n",
    "username = 'elimoore@coca-cola.com'\n",
    "password = os.environ.get(\"KO_PASSWORD\")\n",
    "driver = '{ODBC Driver 17 for SQL Server}'\n",
    "\n",
    "# Connection string\n",
    "connection_string = f'DRIVER={driver};SERVER={server};DATABASE={database};UID={username};PWD={password};Authentication=ActiveDirectoryPassword;Connection Timeout=30'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35aa3623-87e0-495a-9e3c-ef733a932996",
   "metadata": {},
   "source": [
    "#### Identify Brand Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d63377e-34f5-487a-9cca-812d61889b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\O52834\\AppData\\Local\\Temp\\ipykernel_16128\\2170411904.py:13: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  brand_name_data = pd.read_sql(sql_query, connection, params=[brand_id])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coca-Cola/ Coca-Cola Classic\n"
     ]
    }
   ],
   "source": [
    "# SQL query\n",
    "sql_query = \"\"\"\n",
    "    /****** Script for SelectTopNRows command from SSMS  ******/\n",
    "    SELECT distinct(brand) FROM [dm].[Dataset_Product]\n",
    "      where brand_id = ?\n",
    "\"\"\"\n",
    "\n",
    "with pyodbc.connect(connection_string) as connection:\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "    brand_name_data = pd.read_sql(sql_query, connection, params=[brand_id])\n",
    "    \n",
    "    # Retrieve the top row value as a string\n",
    "    if not brand_name_data.empty:\n",
    "        brand_name = brand_name_data.iloc[0]['brand']\n",
    "        print(brand_name)\n",
    "    else:\n",
    "        print(\"No data found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a300e2f1-7396-44f4-8245-42fab7e14a3c",
   "metadata": {},
   "source": [
    "#### Get Brand Logo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0166bbfa-0e3d-47a3-9c2b-3a52ca9c2842",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\O52834\\AppData\\Local\\Temp\\ipykernel_16128\\387349674.py:13: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  brand_name_data = pd.read_sql(sql_query, connection, params=[brand_id,country_id])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://map.cdn.ccnag.com/coca-cola-logo.png\n"
     ]
    }
   ],
   "source": [
    "# SQL query\n",
    "sql_query = \"\"\"\n",
    "    SELECT top 1 [Logo_URL]   \n",
    "    FROM [dm].[Dataset_Product]\n",
    "    where brand_id = ? and country_id=?\n",
    "\"\"\"\n",
    "\n",
    "with pyodbc.connect(connection_string) as connection:\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "    brand_name_data = pd.read_sql(sql_query, connection, params=[brand_id,country_id])\n",
    "    \n",
    "    # Retrieve the top row value as a string\n",
    "    if not brand_name_data.empty:\n",
    "        logo_url = brand_name_data.iloc[0]['Logo_URL']\n",
    "        print(logo_url)\n",
    "    else:\n",
    "        print(\"No data found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656f4a92-0f1b-4dc8-94ae-1cc3efa9aee8",
   "metadata": {},
   "source": [
    "#### Specify the location of the PPT Template File and Final Pasting Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a7a48f7d-dec8-437a-9ed8-d6c740de9efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "template_path = r\"C:\\Users\\O52834\\OneDrive - The Coca-Cola Company\\Documents\\BEACH\\W+ Modeling\\Weekly_Plus_Drivers_Template.pptx\"\n",
    "output_path = fr\"C:\\Users\\O52834\\OneDrive - The Coca-Cola Company\\Documents\\BEACH\\W+ Modeling\\Iteration Outputs\\{country_id}_{brand_id}.pptx\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ffe1b5-f112-460d-ba2c-68709113adba",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Prologue: Identifying best leading indicator of Weekly+\n",
    "This script demonstrates the correlation between Weekly+ and key leading indicators like Past 7 Day Weekly+ and Past 7 Day Incidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6471e114-4808-4adc-bfe1-98c16c70342c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DAX query with dynamic drink type\n",
    "dax_query = f\"\"\"\n",
    "// DAX Query\n",
    "DEFINE\n",
    "    VAR __DS0FilterTable = \n",
    "        TREATAS({{\"12MMT\"}}, '3 Time Period'[Period_Type])\n",
    "\n",
    "    VAR __DS0FilterTable2 = \n",
    "        TREATAS({{\"RTD\"}}, '4 Product'[RTD_NRTD])\n",
    "\n",
    "    VAR __DS0FilterTable3 = \n",
    "        TREATAS({{\"{drink_type}\"}}, '4 Product'[Drink Type])\n",
    "\n",
    "    VAR __DS0Core = \n",
    "        SUMMARIZECOLUMNS(\n",
    "            '5 Demographics and Geography'[Country_ID],\n",
    "            '3 Time Period'[Month_Name],\n",
    "            '3 Time Period'[Month_MMT_ID],\n",
    "            '4 Product'[Trademark],\n",
    "            __DS0FilterTable,\n",
    "            __DS0FilterTable2,\n",
    "            __DS0FilterTable3,\n",
    "            \"WeeklyPlus\", '1 Measures'[Weekly+ Incidence (% weighted)],\n",
    "            \"P7DWeeklyPlus\", '1 Measures'[Past 7 Day Weekly+ Incidence (% weighted)],\n",
    "            \"P7D\", '1 Measures'[Past 7 Day Drinkers (% weighted)],\n",
    "            \"Total_Drinks\", '1 Measures'[Total Drinks]\n",
    "        )\n",
    "\n",
    "EVALUATE\n",
    "    __DS0Core\n",
    "\n",
    "ORDER BY\n",
    "    '5 Demographics and Geography'[Country_ID],\n",
    "    '3 Time Period'[Month_MMT_ID],\n",
    "    '3 Time Period'[Month_Name],\n",
    "    '4 Product'[Trademark]\n",
    "\"\"\"\n",
    "\n",
    "# Use Pyadomd context manager to handle the connection\n",
    "with Pyadomd(pbi_connection_string) as conn:\n",
    "    with conn.cursor().execute(dax_query) as cur:\n",
    "        power_bi_data = pd.DataFrame(cur.fetchall(), columns=[desc[0] for desc in cur.description])\n",
    "\n",
    "# Optionally, print the top 5 rows to confirm the data was retrieved correctly\n",
    "print(power_bi_data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97618f3-323b-4531-961c-38cfa9ba8a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary mapping old column names to new names\n",
    "column_mapping = {\n",
    "    '5 Demographics and Geography[Country_ID]': 'Country_ID',\n",
    "    '3 Time Period[Month_Name]': 'Month_Name',\n",
    "    '3 Time Period[Month_MMT_ID]': 'Month_MMT_ID',\n",
    "    '4 Product[Trademark]': 'Trademark',\n",
    "    '[WeeklyPlus]': 'WeeklyPlus',\n",
    "    '[P7DWeeklyPlus]': 'P7DWeeklyPlus',\n",
    "    '[P7D]': 'P7D',\n",
    "    '[Total_Drinks]': 'Total Drinks'\n",
    "}\n",
    "\n",
    "# Rename the columns using the mapping dictionary\n",
    "df_copy = power_bi_data.copy()\n",
    "df_copy.rename(columns=column_mapping, inplace=True)\n",
    "\n",
    "# Convert categorical variables into numerical values if needed\n",
    "df_copy['Country_ID'] = pd.factorize(df_copy['Country_ID'])[0]\n",
    "df_copy['Trademark'] = pd.factorize(df_copy['Trademark'])[0]\n",
    "\n",
    "# Convert columns to numeric, coerce errors to NaN\n",
    "df_copy['P7D'] = pd.to_numeric(df_copy['P7D'], errors='coerce')\n",
    "df_copy['P7DWeeklyPlus'] = pd.to_numeric(df_copy['P7DWeeklyPlus'], errors='coerce')\n",
    "df_copy['WeeklyPlus'] = pd.to_numeric(df_copy['WeeklyPlus'], errors='coerce')\n",
    "df_copy['Total Drinks'] = pd.to_numeric(df_copy['Total Drinks'], errors='coerce')\n",
    "\n",
    "# Drop rows with any NaN values in the relevant columns\n",
    "df_copy = df_copy.dropna(subset=['P7D', 'P7DWeeklyPlus', 'WeeklyPlus', 'Total Drinks'])\n",
    "\n",
    "# Calculate Pearson correlation between WeeklyPlus and P7D\n",
    "correlation_p7d = df_copy['WeeklyPlus'].corr(df_copy['P7D'])\n",
    "# Calculate Pearson correlation between WeeklyPlus and P7DWeeklyPlus\n",
    "correlation_p7dweeklyplus = df_copy['WeeklyPlus'].corr(df_copy['P7DWeeklyPlus'])\n",
    "# Calculate Pearson correlation between WeeklyPlus and Total Drinks\n",
    "correlation_totaldrinks = df_copy['WeeklyPlus'].corr(df_copy['Total Drinks'])\n",
    "# Calculate Pearson correlation between P7D and Total Drinks\n",
    "correlation_drinks_p7d = df_copy['P7D'].corr(df_copy['Total Drinks'])\n",
    "# Calculate Pearson correlation between P7D and Total Drinks\n",
    "correlation_drinks_p7dw = df_copy['P7DWeeklyPlus'].corr(df_copy['Total Drinks'])\n",
    "\n",
    "# Print the correlation coefficients\n",
    "print(f\"Correlation between WeeklyPlus and P7D: {correlation_p7d:.4f}\")\n",
    "print(f\"Correlation between WeeklyPlus and P7DWeeklyPlus: {correlation_p7dweeklyplus:.4f}\")\n",
    "print(f\"Correlation between WeeklyPlus and Total Drinks: {correlation_totaldrinks:.4f}\")\n",
    "print(f\"Correlation between P7D and Total Drinks: {correlation_drinks_p7d:.4f}\")\n",
    "print(f\"Correlation between P7D WeeklyPlus and Total Drinks: {correlation_drinks_p7dw:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c806e08e-94e5-4e05-88ca-bca2d97c34bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run a simple linear regression to show how strong the relationship is between P7D Weekly+ and Weekly+\n",
    "\n",
    "# Define the target variable\n",
    "y = df_copy['WeeklyPlus']\n",
    "y2 = df_copy['P7D']\n",
    "\n",
    "# Model 1: WeeklyPlus = f(Country_ID, Trademark, P7D)\n",
    "X1 = df_copy[['Country_ID', 'Trademark', 'P7D']]\n",
    "X1 = sm.add_constant(X1)  # Adds a constant term to the predictor\n",
    "model1 = sm.OLS(y, X1).fit()\n",
    "r2_model1 = model1.rsquared\n",
    "\n",
    "# Model 2: WeeklyPlus = f(Country_ID, Trademark, P7DWeeklyPlus)\n",
    "X2 = df_copy[['Country_ID', 'Trademark', 'P7DWeeklyPlus']]\n",
    "X2 = sm.add_constant(X2)  # Adds a constant term to the predictor\n",
    "model2 = sm.OLS(y, X2).fit()\n",
    "r2_model2 = model2.rsquared\n",
    "\n",
    "# Model 3: WeeklyPlus = f(Country_ID, Trademark, TotalDrinks)\n",
    "X2 = df_copy[['Country_ID', 'Trademark', 'Total Drinks']]\n",
    "X2 = sm.add_constant(X2)  # Adds a constant term to the predictor\n",
    "model2 = sm.OLS(y, X2).fit()\n",
    "r2_model3 = model2.rsquared\n",
    "\n",
    "# Model 4: TotalDrinks = f(Country_ID, Trademark, P7D)\n",
    "X2 = df_copy[['Country_ID', 'Trademark', 'Total Drinks']]\n",
    "X2 = sm.add_constant(X2)  # Adds a constant term to the predictor\n",
    "model2 = sm.OLS(y2, X2).fit()\n",
    "r2_model4 = model2.rsquared\n",
    "\n",
    "print(f\"Provided the country, trademark, and P7D or P7DWeeklyPlus, we can confidently estimate Weekly+.\")\n",
    "print(f\"R² for Equation 1 (WeeklyPlus = f(Country_ID, Trademark, P7D)): {r2_model1:.4f}\")\n",
    "print(f\"R² for Equation 2 (WeeklyPlus = f(Country_ID, Trademark, P7DWeeklyPlus)): {r2_model2:.4f}\")\n",
    "print(f\"R² for Equation 3 (WeeklyPlus = f(Country_ID, Trademark, Total Drinks)): {r2_model3:.4f}\")\n",
    "print(f\"R² for Equation 4 (Drinks = f(Country_ID, Trademark, P7D)): {r2_model4:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ec58a8-8979-4bbb-a143-5fc29de1a6b1",
   "metadata": {},
   "source": [
    "## Get Data for Modeling Weekly+\n",
    "Using SQL and Azure, acquire the BEACH data for modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5633ef-0ad4-4c56-b5db-70d4c0eb724c",
   "metadata": {},
   "source": [
    "#### Diary Data\n",
    "This script connects live to the BEACH SQL Server and pulls down relevant diary data for the particular brand and country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdb9d536-40c8-41df-bd1e-b4117e0294c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\O52834\\AppData\\Local\\Temp\\ipykernel_16128\\2999501368.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  diarydata = pd.read_sql(sql_query, connection, params=[country_id, brand_id])\n"
     ]
    }
   ],
   "source": [
    "# SQL query\n",
    "sql_query = \"\"\"\n",
    "    /****** Script for SelectTopNRows command from SSMS  ******/\n",
    "    SELECT [Respondent_ID]\n",
    "          ,right(Month_ID,2) as Month_of_Year\n",
    "          ,case\n",
    "            when [Frequency_Name] = 'Multiple times per week' then 1\n",
    "            when [Frequency_Name] = 'Once a week' then 1\n",
    "            when [Frequency_Name] = 'Daily' then 1\n",
    "            else 0 end Frequency\n",
    "          ,CASE\n",
    "    \t\twhen [Day_Name] = 'Saturday' or [Day_Name] = 'Sunday' then 1 else 0 end Weekend\n",
    "          ,[DayPart_Name]\n",
    "          ,[Where_Name]\n",
    "          ,[Who_Group_HL]\n",
    "          ,[Bought_Name]\n",
    "          ,[IC/FC-SS/MS]\n",
    "          ,[Channel]\n",
    "          ,[Reason_Energize]\n",
    "          ,[Reason_Celebrate]\n",
    "          ,[Reason_Stay]\n",
    "          ,[Reason_Rehydrate]\n",
    "          ,[Reason_Cheer]\n",
    "          ,[Reason_Close]\n",
    "          ,[Reason_Cool]\n",
    "          ,[Reason_Nutritious]\n",
    "          ,[Reason_Focus]\n",
    "          ,[Reason_Complement]\n",
    "          ,[Reason_Confident]\n",
    "          ,[Reason_Taste]\n",
    "          ,[Reason_Reward]\n",
    "          ,[Reason_Restore]\n",
    "          ,[Reason_Performance]\n",
    "          ,[Reason_Other]\n",
    "          ,[High-Level-Occasions]\n",
    "      FROM [dm].[Dataset_Diary_SS]\n",
    "      where country_id= ? and brand_id= ?\n",
    "\"\"\"\n",
    "\n",
    "with pyodbc.connect(connection_string) as connection:\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "    diarydata = pd.read_sql(sql_query, connection, params=[country_id, brand_id])\n",
    "    df = diarydata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4822d247-da32-433d-8dae-587c9b06896c",
   "metadata": {},
   "source": [
    "#### Equity/Imagery Data\n",
    "This script connects to SQL Server and pulls down equity data for the particular brand and country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ee7b895-796c-472e-9061-a4c6a152837b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\O52834\\AppData\\Local\\Temp\\ipykernel_16128\\1980386704.py:117: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  equitydata = pd.read_sql(sql_query, connection, params=[country_id, brand_id, country_id, brand_id, country_id, brand_id])\n"
     ]
    }
   ],
   "source": [
    "# SQL query\n",
    "sql_query = \"\"\"\n",
    "    /****** Script for SelectTopNRows command from SSMS  ******/\n",
    "    WITH a AS (\n",
    "    SELECT \n",
    "        index_resp,\n",
    "        Image_Name,\n",
    "        Country_ID,\n",
    "        Brand_ID\n",
    "    FROM \n",
    "        dm.Dataset_Imagery\n",
    "\tWHERE \n",
    "\t\tCountry_ID = ? \n",
    "\t\tAND Brand_ID = ?\n",
    "\t),\n",
    "\n",
    "b as(\n",
    "\n",
    "SELECT \n",
    "    index_resp,\n",
    "    MAX(CASE WHEN Image_Name = 'Encourages me to try new things' THEN 1 ELSE 0 END) AS [Encourages me to try new things],\n",
    "    MAX(CASE WHEN Image_Name = 'Is a youthful brand' THEN 1 ELSE 0 END) AS [Is a youthful brand],\n",
    "    MAX(CASE WHEN Image_Name = 'Is a brand for everyone' THEN 1 ELSE 0 END) AS [Is a brand for everyone],\n",
    "    MAX(CASE WHEN Image_Name = 'Has a flavor I enjoy' THEN 1 ELSE 0 END) AS [Has a flavor I enjoy],\n",
    "    MAX(CASE WHEN Image_Name = 'Shares my values' THEN 1 ELSE 0 END) AS [Shares my values],\n",
    "    MAX(CASE WHEN Image_Name = 'Offers quality I can trust' THEN 1 ELSE 0 END) AS [Offers quality I can trust],\n",
    "    MAX(CASE WHEN Image_Name = 'Cares about the environment' THEN 1 ELSE 0 END) AS [Cares about the environment],\n",
    "    MAX(CASE WHEN Image_Name = 'Is easy to find in stores' THEN 1 ELSE 0 END) AS [Is easy to find in stores],\n",
    "    MAX(CASE WHEN Image_Name = 'Has a unique taste' THEN 1 ELSE 0 END) AS [Has a unique taste],\n",
    "    MAX(CASE WHEN Image_Name = 'Gives me an energy boost' THEN 1 ELSE 0 END) AS [Gives me an energy boost],\n",
    "    MAX(CASE WHEN Image_Name = 'Goes well with food' THEN 1 ELSE 0 END) AS [Goes well with food],\n",
    "    MAX(CASE WHEN Image_Name = 'Brings me happiness' THEN 1 ELSE 0 END) AS [Brings me happiness],\n",
    "    MAX(CASE WHEN Image_Name = 'Is available in convenient packaging' THEN 1 ELSE 0 END) AS [Is available in convenient packaging],\n",
    "    MAX(CASE WHEN Image_Name = 'Makes moments special' THEN 1 ELSE 0 END) AS [Makes moments special],\n",
    "    MAX(CASE WHEN Image_Name = 'Has a refreshing taste' THEN 1 ELSE 0 END) AS [Has a refreshing taste],\n",
    "    MAX(CASE WHEN Image_Name = 'Helps keep me going' THEN 1 ELSE 0 END) AS [Helps keep me going],\n",
    "    MAX(CASE WHEN Image_Name = 'Has the right amount of calories' THEN 1 ELSE 0 END) AS [Has the right amount of calories],\n",
    "    MAX(CASE WHEN Image_Name = 'Gives me confidence to be myself' THEN 1 ELSE 0 END) AS [Gives me confidence to be myself]\n",
    "FROM \n",
    "    a\n",
    "\n",
    "GROUP BY\n",
    "\tindex_resp),\n",
    "\n",
    "c as (\n",
    "\tSELECT \n",
    "\t\t\tindex_resp\n",
    "\t\t  ,[Familiarity_Name]\n",
    "\t\t  ,[Cons_Name]\n",
    "\t\t  ,[Affinity_Name]\n",
    "\t\t  ,[Cons_Segment]\n",
    "\t\t  ,[Unique_Name]\n",
    "\t\t  ,[MNeeds_Name]\n",
    "\t\t  ,[Dynamic_Name]\n",
    "\t\t  ,[Price_Name]\n",
    "\t\t  ,[Worth_Name]\n",
    "\t  FROM [dm].[Dataset_Equity]\n",
    "\n",
    "\t  where country_id= ? and brand_id= ?\n",
    "  ),\n",
    "\n",
    "  d1 as (\n",
    "\n",
    "\t  SELECT index_resp\n",
    "\t\t  ,case\n",
    "\t\t\twhen [Frequency_Name] = 'Multiple times per week' then 1\n",
    "\t\t\twhen [Frequency_Name] = 'Once a week' then 1\n",
    "\t\t\twhen [Frequency_Name] = 'Daily' then 1\n",
    "\t\t\telse 0 end Frequency\n",
    "\t  FROM [dm].[Dataset_Diary_SS]\n",
    "\n",
    "\t  where country_id= ? and brand_id= ?\n",
    "\n",
    "\t),\n",
    "\n",
    "d as (\n",
    "\n",
    "\t  SELECT index_resp, max(Frequency) as Frequency\n",
    "\t  FROM d1\n",
    "\n",
    "\t  group by index_resp\n",
    "\n",
    "\n",
    ")\n",
    "\n",
    "\t\tSelect \n",
    "\t\t\tc.index_resp\n",
    "\t\t\t,d.Frequency\n",
    "\t\t\t,c.[Familiarity_Name]\n",
    "\t\t\t,c.[Cons_Name]\n",
    "\t\t\t,c.[Affinity_Name]\n",
    "\t\t\t,c.[Cons_Segment]\n",
    "\t\t\t,c.[Unique_Name]\n",
    "\t\t\t,c.[MNeeds_Name]\n",
    "\t\t\t,c.[Dynamic_Name]\n",
    "\t\t\t,c.[Price_Name]\n",
    "\t\t\t,c.[Worth_Name]\n",
    "\t\t\t, b.*\n",
    "\t\tfrom c\n",
    "\n",
    "\n",
    "\t\tleft join b on b.index_resp = c.index_resp\n",
    "\n",
    "\t\tleft join d on d.index_resp = c.index_resp\n",
    "\n",
    "\t\tleft join dm.Dataset_Metrics q on c.index_resp = q.index_resp\n",
    "\n",
    "\t\twhere q.survey_flag<>'Equity'\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "with pyodbc.connect(connection_string) as connection:\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "    equitydata = pd.read_sql(sql_query, connection, params=[country_id, brand_id, country_id, brand_id, country_id, brand_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db89974-f3cd-4414-b1f9-4282509f0a54",
   "metadata": {},
   "source": [
    "## Creating Driver Models\n",
    "Using Random Forest, create models to understand what makes someone become Weekly+"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176f98da-b8cd-416b-8c32-9d8d707c9f6c",
   "metadata": {},
   "source": [
    "#### Diary Drivers\n",
    "This script runs a random forest to see what the primary behavioral variables contribute to users becoming weekly+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a5cc71f-e16c-45ee-b6c1-f1ae3ae097bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.10      0.15      1242\n",
      "           1       0.89      0.97      0.93      9533\n",
      "\n",
      "    accuracy                           0.87     10775\n",
      "   macro avg       0.60      0.54      0.54     10775\n",
      "weighted avg       0.82      0.87      0.84     10775\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the data\n",
    "X = diarydata.drop(columns=['Respondent_ID', 'Frequency'])\n",
    "y = diarydata['Frequency']\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Preprocessing for numerical data (standard scaling)\n",
    "numerical_transformer = StandardScaler()\n",
    "\n",
    "# Preprocessing for categorical data (one-hot encoding)\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Define the model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "# Create and evaluate the pipeline\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('model', model)])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Feature importance\n",
    "feature_names = list(numerical_cols) + list(clf.named_steps['preprocessor'].transformers_[1][1].get_feature_names_out(categorical_cols))\n",
    "importances = clf.named_steps['model'].feature_importances_\n",
    "\n",
    "# Combine feature names and importances into a DataFrame\n",
    "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances}).sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a1c384-51be-45db-9373-f1d74c197139",
   "metadata": {},
   "source": [
    "#### Quantifying Impact of Changes in Behavior on Weekly+\n",
    "This script determines the top behavioral drivers and the impact of changing them on someone's likelihood of becoming Weekly+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a54e3fae-ede3-4ca1-a4a0-c65d635975af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Feature  Importance  \\\n",
      "27                     Bought_Name_I bought it myself    0.019617   \n",
      "26                                 Where_Name_At Home    0.020199   \n",
      "33  Channel_Grocery store (not a chain)/ Independe...    0.014928   \n",
      "22  Channel_Supermarket/ Hypermarket/ warehouse store    0.020755   \n",
      "12                                  IC/FC-SS/MS_IC-SS    0.024729   \n",
      "5          DayPart_Name_Midday (between 11am and 2pm)    0.030083   \n",
      "2                         High-Level-Occasions_Eating    0.031560   \n",
      "18                                 Who_Group_HL_Alone    0.021841   \n",
      "45   DayPart_Name_Early Morning (between 6am and 8am)    0.007458   \n",
      "44              High-Level-Occasions_Starting The Day    0.008069   \n",
      "31    DayPart_Name_Mid Morning (between 8am and 11am)    0.016775   \n",
      "51  Bought_Name_Not applicable - drink was made at...    0.001681   \n",
      "37    Channel_Convenience stores/ Gas/ Petrol Station    0.012731   \n",
      "52                                     Bought_Name_NA    0.000009   \n",
      "54                                        Reason_Stay    0.000000   \n",
      "55                                   Reason_Celebrate    0.000000   \n",
      "56                                    Reason_Energize    0.000000   \n",
      "53                                   Reason_Rehydrate    0.000000   \n",
      "61                                       Reason_Other    0.000000   \n",
      "63                                     Reason_Restore    0.000000   \n",
      "62                                 Reason_Performance    0.000000   \n",
      "64                                      Reason_Reward    0.000000   \n",
      "67                                        Reason_Cool    0.000000   \n",
      "66                                       Reason_Close    0.000000   \n",
      "68                                  Reason_Nutritious    0.000000   \n",
      "57                                       Reason_Taste    0.000000   \n",
      "58                                   Reason_Confident    0.000000   \n",
      "59                                  Reason_Complement    0.000000   \n",
      "60                                       Reason_Focus    0.000000   \n",
      "65                                       Reason_Cheer    0.000000   \n",
      "\n",
      "    Change in Predicted Probability (%)  \n",
      "27                             5.147070  \n",
      "26                             3.708645  \n",
      "33                             1.982417  \n",
      "22                             1.866099  \n",
      "12                             1.635552  \n",
      "5                              0.912524  \n",
      "2                              0.708786  \n",
      "18                             0.600023  \n",
      "45                             0.469842  \n",
      "44                             0.350703  \n",
      "31                             0.133781  \n",
      "51                             0.105608  \n",
      "37                             0.089727  \n",
      "52                             0.023108  \n",
      "54                             0.000000  \n",
      "55                             0.000000  \n",
      "56                             0.000000  \n",
      "53                             0.000000  \n",
      "61                             0.000000  \n",
      "63                             0.000000  \n",
      "62                             0.000000  \n",
      "64                             0.000000  \n",
      "67                             0.000000  \n",
      "66                             0.000000  \n",
      "68                             0.000000  \n",
      "57                             0.000000  \n",
      "58                             0.000000  \n",
      "59                             0.000000  \n",
      "60                             0.000000  \n",
      "65                             0.000000  \n",
      "             Feature  Min Value Predicted Probability (%)  \\\n",
      "0            Weekend                            88.827403   \n",
      "1    Reason_Energize                            88.474435   \n",
      "2   Reason_Celebrate                            88.474435   \n",
      "3        Reason_Stay                            88.474435   \n",
      "4   Reason_Rehydrate                            88.474435   \n",
      "5       Reason_Cheer                            88.474435   \n",
      "6       Reason_Close                            88.474435   \n",
      "7        Reason_Cool                            88.474435   \n",
      "8  Reason_Nutritious                            88.474435   \n",
      "9       Reason_Focus                            88.474435   \n",
      "\n",
      "   Max Value Predicted Probability (%)  Change in Predicted Probability (%)  \n",
      "0                            87.457216                            -1.370187  \n",
      "1                            88.474435                             0.000000  \n",
      "2                            88.474435                             0.000000  \n",
      "3                            88.474435                             0.000000  \n",
      "4                            88.474435                             0.000000  \n",
      "5                            88.474435                             0.000000  \n",
      "6                            88.474435                             0.000000  \n",
      "7                            88.474435                             0.000000  \n",
      "8                            88.474435                             0.000000  \n",
      "9                            88.474435                             0.000000  \n",
      "Feature: Bought_Name_I bought it myself\n",
      "Min value predicted probability: 84.06%\n",
      "Max value predicted probability: 89.21%\n",
      "Change in predicted probability: +5.15%\n",
      "For example, moving the perception of 'Bought_Name_I bought it myself' from a low level to a high level can increase the likelihood of frequent usage (Frequency = 1) by 5.15%.\n",
      "Our model suggests a probability increase from 84.06% to 89.21% when the feature value is maximized.\n",
      "\n",
      "Feature: Where_Name_At Home\n",
      "Min value predicted probability: 85.03%\n",
      "Max value predicted probability: 88.74%\n",
      "Change in predicted probability: +3.71%\n",
      "For example, moving the perception of 'Where_Name_At Home' from a low level to a high level can increase the likelihood of frequent usage (Frequency = 1) by 3.71%.\n",
      "Our model suggests a probability increase from 85.03% to 88.74% when the feature value is maximized.\n",
      "\n",
      "Feature: Channel_Grocery store (not a chain)/ Independent store\n",
      "Min value predicted probability: 88.01%\n",
      "Max value predicted probability: 89.99%\n",
      "Change in predicted probability: +1.98%\n",
      "For example, moving the perception of 'Channel_Grocery store (not a chain)/ Independent store' from a low level to a high level can increase the likelihood of frequent usage (Frequency = 1) by 1.98%.\n",
      "Our model suggests a probability increase from 88.01% to 89.99% when the feature value is maximized.\n",
      "\n",
      "Feature: Channel_Supermarket/ Hypermarket/ warehouse store\n",
      "Min value predicted probability: 87.65%\n",
      "Max value predicted probability: 89.51%\n",
      "Change in predicted probability: +1.87%\n",
      "For example, moving the perception of 'Channel_Supermarket/ Hypermarket/ warehouse store' from a low level to a high level can increase the likelihood of frequent usage (Frequency = 1) by 1.87%.\n",
      "Our model suggests a probability increase from 87.65% to 89.51% when the feature value is maximized.\n",
      "\n",
      "Feature: IC/FC-SS/MS_IC-SS\n",
      "Min value predicted probability: 87.21%\n",
      "Max value predicted probability: 88.85%\n",
      "Change in predicted probability: +1.64%\n",
      "For example, moving the perception of 'IC/FC-SS/MS_IC-SS' from a low level to a high level can increase the likelihood of frequent usage (Frequency = 1) by 1.64%.\n",
      "Our model suggests a probability increase from 87.21% to 88.85% when the feature value is maximized.\n",
      "\n",
      "Feature: DayPart_Name_Midday (between 11am and 2pm)\n",
      "Min value predicted probability: 88.03%\n",
      "Max value predicted probability: 88.94%\n",
      "Change in predicted probability: +0.91%\n",
      "For example, moving the perception of 'DayPart_Name_Midday (between 11am and 2pm)' from a low level to a high level can increase the likelihood of frequent usage (Frequency = 1) by 0.91%.\n",
      "Our model suggests a probability increase from 88.03% to 88.94% when the feature value is maximized.\n",
      "\n",
      "Feature: High-Level-Occasions_Eating\n",
      "Min value predicted probability: 87.92%\n",
      "Max value predicted probability: 88.62%\n",
      "Change in predicted probability: +0.71%\n",
      "For example, moving the perception of 'High-Level-Occasions_Eating' from a low level to a high level can increase the likelihood of frequent usage (Frequency = 1) by 0.71%.\n",
      "Our model suggests a probability increase from 87.92% to 88.62% when the feature value is maximized.\n",
      "\n",
      "Feature: Who_Group_HL_Alone\n",
      "Min value predicted probability: 88.08%\n",
      "Max value predicted probability: 88.68%\n",
      "Change in predicted probability: +0.60%\n",
      "For example, moving the perception of 'Who_Group_HL_Alone' from a low level to a high level can increase the likelihood of frequent usage (Frequency = 1) by 0.60%.\n",
      "Our model suggests a probability increase from 88.08% to 88.68% when the feature value is maximized.\n",
      "\n",
      "Feature: DayPart_Name_Early Morning (between 6am and 8am)\n",
      "Min value predicted probability: 88.45%\n",
      "Max value predicted probability: 88.92%\n",
      "Change in predicted probability: +0.47%\n",
      "For example, moving the perception of 'DayPart_Name_Early Morning (between 6am and 8am)' from a low level to a high level can increase the likelihood of frequent usage (Frequency = 1) by 0.47%.\n",
      "Our model suggests a probability increase from 88.45% to 88.92% when the feature value is maximized.\n",
      "\n",
      "Feature: High-Level-Occasions_Starting The Day\n",
      "Min value predicted probability: 88.45%\n",
      "Max value predicted probability: 88.80%\n",
      "Change in predicted probability: +0.35%\n",
      "For example, moving the perception of 'High-Level-Occasions_Starting The Day' from a low level to a high level can increase the likelihood of frequent usage (Frequency = 1) by 0.35%.\n",
      "Our model suggests a probability increase from 88.45% to 88.80% when the feature value is maximized.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PDP analysis for all features without plotting\n",
    "results = []\n",
    "X_transformed = clf.named_steps['preprocessor'].transform(X)\n",
    "\n",
    "for feature_name in feature_names:\n",
    "    feature_index = feature_names.index(feature_name)\n",
    "    \n",
    "    # Generate Partial Dependence values for the current feature without plotting\n",
    "    pdp = partial_dependence(clf.named_steps['model'], X_transformed, [feature_index], grid_resolution=50)\n",
    "    \n",
    "    # Extract the averaged predicted probabilities\n",
    "    pdp_values = pdp['average'].ravel()\n",
    "    \n",
    "    # Find the change in probability when moving from min to max value of the feature\n",
    "    min_value_prob = pdp_values[0]\n",
    "    max_value_prob = pdp_values[-1]\n",
    "    prob_change = max_value_prob - min_value_prob\n",
    "    \n",
    "    # Convert to percentages\n",
    "    min_value_prob_percent = min_value_prob * 100\n",
    "    max_value_prob_percent = max_value_prob * 100\n",
    "    prob_change_percent = prob_change * 100\n",
    "    \n",
    "    result = {\n",
    "        'Feature': feature_name,\n",
    "        'Min Value Predicted Probability (%)': min_value_prob_percent,\n",
    "        'Max Value Predicted Probability (%)': max_value_prob_percent,\n",
    "        'Change in Predicted Probability (%)': prob_change_percent\n",
    "    }\n",
    "    results.append(result)\n",
    "\n",
    "# Convert results to a DataFrame for easier visualization\n",
    "pdp_analysis_df = pd.DataFrame(results)\n",
    "\n",
    "# Merge feature_importance_df with pdp_analysis_df on 'Feature' column\n",
    "feature_importance_df = feature_importance_df.merge(pdp_analysis_df[['Feature', 'Change in Predicted Probability (%)']], on='Feature', how='left')\n",
    "\n",
    "# Sort feature_importance_df by 'Change in Predicted Probability (%)' in descending order\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Change in Predicted Probability (%)', ascending=False)\n",
    "\n",
    "# Display the most important features with added 'Change in Predicted Probability (%)'\n",
    "print(feature_importance_df.head(30))\n",
    "\n",
    "print(pdp_analysis_df.head(10))\n",
    "\n",
    "# Filter out features with negative change and sort by positive change\n",
    "positive_changes_df = pdp_analysis_df[pdp_analysis_df['Change in Predicted Probability (%)'] > 0]\n",
    "top_positive_changes_df = positive_changes_df.sort_values(by='Change in Predicted Probability (%)', ascending=False).head(10)\n",
    "\n",
    "\n",
    "interpretations = \"\"\n",
    "\n",
    "# Interpretations for the top 5 features with positive changes\n",
    "for index, row in top_positive_changes_df.iterrows():\n",
    "    feature_name = row['Feature']\n",
    "    min_value_prob_percent = row['Min Value Predicted Probability (%)']\n",
    "    max_value_prob_percent = row['Max Value Predicted Probability (%)']\n",
    "    prob_change_percent = row['Change in Predicted Probability (%)']\n",
    "    \n",
    "    interpretation = (\n",
    "        f\"Feature: {feature_name}\\n\"\n",
    "        f\"Change in predicted probability: +{prob_change_percent:.2f}%\\n\"\n",
    "        f\"For example, moving the perception of '{feature_name}' from a low level to a high level can increase the likelihood of frequent usage (Frequency = 1) by {prob_change_percent:.2f}%.\\n\"\n",
    "    )\n",
    "    \n",
    "    # Append the interpretation to the string\n",
    "    interpretations += interpretation\n",
    "    \n",
    "    print(f\"Feature: {feature_name}\")\n",
    "    print(f\"Min value predicted probability: {min_value_prob_percent:.2f}%\")\n",
    "    print(f\"Max value predicted probability: {max_value_prob_percent:.2f}%\")\n",
    "    print(f\"Change in predicted probability: +{prob_change_percent:.2f}%\")\n",
    "    print(f\"For example, moving the perception of '{feature_name}' from a low level to a high level can increase the likelihood of frequent usage (Frequency = 1) by {prob_change_percent:.2f}%.\")\n",
    "    print(f\"Our model suggests a probability increase from {min_value_prob_percent:.2f}% to {max_value_prob_percent:.2f}% when the feature value is maximized.\")\n",
    "    print()\n",
    "\n",
    "diary_insight = f\"The following are insights from the behavior (diary) drivers of Weekly+:\\n\\n{interpretations}\\n\\n\"\n",
    "\n",
    "diaryprompt = f\"The following are the top features most important for predicting [Frequency] = 1 in a RandomForest model based on diary (consumer behavior) data:\\n\\n{feature_importance_df.head(10).to_string(index=False)}\\n\\n.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d423af-664f-451b-ab16-9cb93295c45c",
   "metadata": {},
   "source": [
    "#### Equity/Imagery Drivers\n",
    "This script runs a random forest to see what attitudinal/perception variables contribute to users becoming weekly+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcc6cd3d-5c69-4e18-99c3-8c84ecc99644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.70      0.80      1523\n",
      "         1.0       0.37      0.80      0.51       342\n",
      "\n",
      "    accuracy                           0.72      1865\n",
      "   macro avg       0.66      0.75      0.65      1865\n",
      "weighted avg       0.83      0.72      0.75      1865\n",
      "\n",
      "                              Feature  Importance\n",
      "18  Familiarity_Name_Drink most often    0.051077\n",
      "23             Familiarity_Name_Tried    0.045453\n",
      "37             Cons_Segment_Intenders    0.041640\n",
      "29         Affinity_Name_+3 I love it    0.039802\n",
      "11                Brings me happiness    0.037265\n",
      "..                                ...         ...\n",
      "64                    Dynamic_Name_NA    0.000027\n",
      "48                     Unique_Name_NA    0.000024\n",
      "38                    Cons_Segment_NA    0.000017\n",
      "56                     MNeeds_Name_NA    0.000002\n",
      "36                   Affinity_Name_NA    0.000000\n",
      "\n",
      "[77 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values in the 'Frequency' column with 0s\n",
    "equitydata['Frequency'] = equitydata['Frequency'].fillna(0)\n",
    "\n",
    "# Preprocess the data\n",
    "X = equitydata.drop(columns=['index_resp', 'Frequency'])  # Adjust with correct column names\n",
    "y = equitydata['Frequency']\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Preprocessing for numerical data (standard scaling)\n",
    "numerical_transformer = StandardScaler()\n",
    "\n",
    "# Preprocessing for categorical data (one-hot encoding)\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply undersampling to the training data\n",
    "rus = RandomUnderSampler(sampling_strategy='auto', random_state=42)  # Initialize RandomUnderSampler\n",
    "X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)  # Resample only training data\n",
    "\n",
    "# Define the model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "# Create the pipeline\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('model', model)])\n",
    "\n",
    "# Fit the model on the resampled training data\n",
    "clf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Feature importance\n",
    "feature_names = list(numerical_cols) + list(clf.named_steps['preprocessor'].transformers_[1][1].get_feature_names_out(categorical_cols))\n",
    "importances = clf.named_steps['model'].feature_importances_\n",
    "\n",
    "# Combine feature names and importances into a DataFrame\n",
    "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances}).sort_values(by='Importance', ascending=False)\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe91f12-a1b2-4d89-9b0e-66a3b9ae2737",
   "metadata": {},
   "source": [
    "#### Quantifying Impact of Changes in Attitudes/Perceptions on Weekly+\n",
    "Determine the top attitudinal/perception drivers impact on Weekly+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2fed61b-a1f9-4971-a51b-4af0e455c0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       Feature  Importance  \\\n",
      "0            Familiarity_Name_Drink most often    0.051077   \n",
      "3                   Affinity_Name_+3 I love it    0.039802   \n",
      "2                       Cons_Segment_Intenders    0.041640   \n",
      "5        Cons_Name_It would be my first choice    0.030347   \n",
      "6          MNeeds_Name_7 Meets needs very well    0.027698   \n",
      "29                               Unique_Name_6    0.015950   \n",
      "52                                Price_Name_3    0.005104   \n",
      "4                          Brings me happiness    0.037265   \n",
      "11                         Helps keep me going    0.023415   \n",
      "10                        Has a flavor I enjoy    0.023649   \n",
      "18            Familiarity_Name_Drink regularly    0.019511   \n",
      "34                              Dynamic_Name_6    0.014048   \n",
      "15            Gives me confidence to be myself    0.020976   \n",
      "13                  Offers quality I can trust    0.022316   \n",
      "14                      Has a refreshing taste    0.022023   \n",
      "8                           Has a unique taste    0.024248   \n",
      "39                             Affinity_Name_2    0.011554   \n",
      "27                       Worth_Name_Worth more    0.016064   \n",
      "17                     Is a brand for everyone    0.019671   \n",
      "43                              Dynamic_Name_4    0.009835   \n",
      "30                   Is easy to find in stores    0.015237   \n",
      "26                                Price_Name_4    0.016263   \n",
      "9                     Gives me an energy boost    0.023875   \n",
      "20                 Price_Name_7 Costs the most    0.019128   \n",
      "7                        Makes moments special    0.026435   \n",
      "47                               MNeeds_Name_5    0.007058   \n",
      "22                   Worth_Name_Worth the same    0.018777   \n",
      "63                               MNeeds_Name_2    0.000851   \n",
      "35                         Goes well with food    0.013008   \n",
      "64  Familiarity_Name_Heard a lot & never tried    0.000740   \n",
      "\n",
      "    Change in Predicted Probability (%)  \n",
      "0                             11.047639  \n",
      "3                              8.804520  \n",
      "2                              8.150561  \n",
      "5                              5.481609  \n",
      "6                              4.016622  \n",
      "29                             2.145606  \n",
      "52                             1.743643  \n",
      "4                              1.312017  \n",
      "11                             1.310435  \n",
      "10                             1.155707  \n",
      "18                             1.145880  \n",
      "34                             1.081807  \n",
      "15                             0.923235  \n",
      "13                             0.806469  \n",
      "14                             0.766611  \n",
      "8                              0.748599  \n",
      "39                             0.648275  \n",
      "27                             0.640010  \n",
      "17                             0.598990  \n",
      "43                             0.440510  \n",
      "30                             0.416911  \n",
      "26                             0.413236  \n",
      "9                              0.411926  \n",
      "20                             0.411839  \n",
      "7                              0.396687  \n",
      "47                             0.379903  \n",
      "22                             0.262628  \n",
      "63                             0.243447  \n",
      "35                             0.226554  \n",
      "64                             0.128774  \n",
      "                           Feature  Min Value Predicted Probability (%)  \\\n",
      "0  Encourages me to try new things                            40.286078   \n",
      "1              Is a youthful brand                            40.513710   \n",
      "2          Is a brand for everyone                            39.573245   \n",
      "3             Has a flavor I enjoy                            38.866064   \n",
      "4                 Shares my values                            40.126978   \n",
      "5       Offers quality I can trust                            39.083938   \n",
      "6      Cares about the environment                            40.110811   \n",
      "7        Is easy to find in stores                            39.677042   \n",
      "8               Has a unique taste                            39.264880   \n",
      "9         Gives me an energy boost                            39.776289   \n",
      "\n",
      "   Max Value Predicted Probability (%)  Change in Predicted Probability (%)  \n",
      "0                            40.208297                            -0.077781  \n",
      "1                            40.213986                            -0.299724  \n",
      "2                            40.172235                             0.598990  \n",
      "3                            40.021771                             1.155707  \n",
      "4                            40.099904                            -0.027074  \n",
      "5                            39.890407                             0.806469  \n",
      "6                            39.888057                            -0.222755  \n",
      "7                            40.093953                             0.416911  \n",
      "8                            40.013479                             0.748599  \n",
      "9                            40.188215                             0.411926  \n",
      "Feature: Familiarity_Name_Drink most often\n",
      "Min value predicted probability: 36.08%\n",
      "Max value predicted probability: 47.13%\n",
      "Change in predicted probability: +11.05%\n",
      "For example, moving the perception of 'Familiarity_Name_Drink most often' from a low level to a high level can increase the likelihood of frequent usage (Frequency = 1) by 11.05%.\n",
      "Our model suggests a probability increase from 36.08% to 47.13% when the feature value is maximized.\n",
      "\n",
      "Feature: Affinity_Name_+3 I love it\n",
      "Min value predicted probability: 36.89%\n",
      "Max value predicted probability: 45.69%\n",
      "Change in predicted probability: +8.80%\n",
      "For example, moving the perception of 'Affinity_Name_+3 I love it' from a low level to a high level can increase the likelihood of frequent usage (Frequency = 1) by 8.80%.\n",
      "Our model suggests a probability increase from 36.89% to 45.69% when the feature value is maximized.\n",
      "\n",
      "Feature: Cons_Segment_Intenders\n",
      "Min value predicted probability: 38.09%\n",
      "Max value predicted probability: 46.24%\n",
      "Change in predicted probability: +8.15%\n",
      "For example, moving the perception of 'Cons_Segment_Intenders' from a low level to a high level can increase the likelihood of frequent usage (Frequency = 1) by 8.15%.\n",
      "Our model suggests a probability increase from 38.09% to 46.24% when the feature value is maximized.\n",
      "\n",
      "Feature: Cons_Name_It would be my first choice\n",
      "Min value predicted probability: 37.95%\n",
      "Max value predicted probability: 43.44%\n",
      "Change in predicted probability: +5.48%\n",
      "For example, moving the perception of 'Cons_Name_It would be my first choice' from a low level to a high level can increase the likelihood of frequent usage (Frequency = 1) by 5.48%.\n",
      "Our model suggests a probability increase from 37.95% to 43.44% when the feature value is maximized.\n",
      "\n",
      "Feature: MNeeds_Name_7 Meets needs very well\n",
      "Min value predicted probability: 38.70%\n",
      "Max value predicted probability: 42.72%\n",
      "Change in predicted probability: +4.02%\n",
      "For example, moving the perception of 'MNeeds_Name_7 Meets needs very well' from a low level to a high level can increase the likelihood of frequent usage (Frequency = 1) by 4.02%.\n",
      "Our model suggests a probability increase from 38.70% to 42.72% when the feature value is maximized.\n",
      "\n",
      "Feature: Unique_Name_6\n",
      "Min value predicted probability: 39.75%\n",
      "Max value predicted probability: 41.89%\n",
      "Change in predicted probability: +2.15%\n",
      "For example, moving the perception of 'Unique_Name_6' from a low level to a high level can increase the likelihood of frequent usage (Frequency = 1) by 2.15%.\n",
      "Our model suggests a probability increase from 39.75% to 41.89% when the feature value is maximized.\n",
      "\n",
      "Feature: Price_Name_3\n",
      "Min value predicted probability: 40.19%\n",
      "Max value predicted probability: 41.94%\n",
      "Change in predicted probability: +1.74%\n",
      "For example, moving the perception of 'Price_Name_3' from a low level to a high level can increase the likelihood of frequent usage (Frequency = 1) by 1.74%.\n",
      "Our model suggests a probability increase from 40.19% to 41.94% when the feature value is maximized.\n",
      "\n",
      "Feature: Brings me happiness\n",
      "Min value predicted probability: 38.55%\n",
      "Max value predicted probability: 39.86%\n",
      "Change in predicted probability: +1.31%\n",
      "For example, moving the perception of 'Brings me happiness' from a low level to a high level can increase the likelihood of frequent usage (Frequency = 1) by 1.31%.\n",
      "Our model suggests a probability increase from 38.55% to 39.86% when the feature value is maximized.\n",
      "\n",
      "Feature: Helps keep me going\n",
      "Min value predicted probability: 39.00%\n",
      "Max value predicted probability: 40.32%\n",
      "Change in predicted probability: +1.31%\n",
      "For example, moving the perception of 'Helps keep me going' from a low level to a high level can increase the likelihood of frequent usage (Frequency = 1) by 1.31%.\n",
      "Our model suggests a probability increase from 39.00% to 40.32% when the feature value is maximized.\n",
      "\n",
      "Feature: Has a flavor I enjoy\n",
      "Min value predicted probability: 38.87%\n",
      "Max value predicted probability: 40.02%\n",
      "Change in predicted probability: +1.16%\n",
      "For example, moving the perception of 'Has a flavor I enjoy' from a low level to a high level can increase the likelihood of frequent usage (Frequency = 1) by 1.16%.\n",
      "Our model suggests a probability increase from 38.87% to 40.02% when the feature value is maximized.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PDP analysis for all features without plotting\n",
    "results = []\n",
    "X_transformed = clf.named_steps['preprocessor'].transform(X)\n",
    "\n",
    "for feature_name in feature_names:\n",
    "    feature_index = feature_names.index(feature_name)\n",
    "    \n",
    "    # Generate Partial Dependence values for the current feature without plotting\n",
    "    pdp = partial_dependence(clf.named_steps['model'], X_transformed, [feature_index], grid_resolution=50)\n",
    "    \n",
    "    # Extract the averaged predicted probabilities\n",
    "    pdp_values = pdp['average'].ravel()\n",
    "    \n",
    "    # Find the change in probability when moving from min to max value of the feature\n",
    "    min_value_prob = pdp_values[0]\n",
    "    max_value_prob = pdp_values[-1]\n",
    "    prob_change = max_value_prob - min_value_prob\n",
    "    \n",
    "    # Convert to percentages\n",
    "    min_value_prob_percent = min_value_prob * 100\n",
    "    max_value_prob_percent = max_value_prob * 100\n",
    "    prob_change_percent = prob_change * 100\n",
    "    \n",
    "    result = {\n",
    "        'Feature': feature_name,\n",
    "        'Min Value Predicted Probability (%)': min_value_prob_percent,\n",
    "        'Max Value Predicted Probability (%)': max_value_prob_percent,\n",
    "        'Change in Predicted Probability (%)': prob_change_percent\n",
    "    }\n",
    "    results.append(result)\n",
    "\n",
    "# Convert results to a DataFrame for easier visualization\n",
    "pdp_analysis_df = pd.DataFrame(results)\n",
    "\n",
    "# Merge feature_importance_df with pdp_analysis_df on 'Feature' column\n",
    "feature_importance_df = feature_importance_df.merge(pdp_analysis_df[['Feature', 'Change in Predicted Probability (%)']], on='Feature', how='left')\n",
    "\n",
    "# Sort feature_importance_df by 'Change in Predicted Probability (%)' in descending order\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Change in Predicted Probability (%)', ascending=False)\n",
    "\n",
    "# Display the most important features with added 'Change in Predicted Probability (%)'\n",
    "print(feature_importance_df.head(30))\n",
    "\n",
    "print(pdp_analysis_df.head(10))\n",
    "\n",
    "# Filter out features with negative change and sort by positive change\n",
    "positive_changes_df = pdp_analysis_df[pdp_analysis_df['Change in Predicted Probability (%)'] > 0]\n",
    "top_positive_changes_df = positive_changes_df.sort_values(by='Change in Predicted Probability (%)', ascending=False).head(10)\n",
    "\n",
    "interpretations = \"\"\n",
    "\n",
    "# Interpretations for the top 5 features with positive changes\n",
    "for index, row in top_positive_changes_df.iterrows():\n",
    "    feature_name = row['Feature']\n",
    "    min_value_prob_percent = row['Min Value Predicted Probability (%)']\n",
    "    max_value_prob_percent = row['Max Value Predicted Probability (%)']\n",
    "    prob_change_percent = row['Change in Predicted Probability (%)']\n",
    "    \n",
    "    interpretation = (\n",
    "        f\"Feature: {feature_name}\\n\"\n",
    "        f\"Change in predicted probability: +{prob_change_percent:.2f}%\\n\"\n",
    "        f\"For example, moving the perception of '{feature_name}' from a low level to a high level can increase the likelihood of frequent usage (Frequency = 1) by {prob_change_percent:.2f}%.\\n\"\n",
    "    )\n",
    "    \n",
    "    # Append the interpretation to the string\n",
    "    interpretations += interpretation\n",
    "    \n",
    "    print(f\"Feature: {feature_name}\")\n",
    "    print(f\"Min value predicted probability: {min_value_prob_percent:.2f}%\")\n",
    "    print(f\"Max value predicted probability: {max_value_prob_percent:.2f}%\")\n",
    "    print(f\"Change in predicted probability: +{prob_change_percent:.2f}%\")\n",
    "    print(f\"For example, moving the perception of '{feature_name}' from a low level to a high level can increase the likelihood of frequent usage (Frequency = 1) by {prob_change_percent:.2f}%.\")\n",
    "    print(f\"Our model suggests a probability increase from {min_value_prob_percent:.2f}% to {max_value_prob_percent:.2f}% when the feature value is maximized.\")\n",
    "    print()\n",
    "\n",
    "equity_insight = f\"The following are insights from the equity/imagery drivers of Weekly+:\\n\\n{interpretations}\\n\\n\"\n",
    "\n",
    "equityprompt = f\"The following are the top features most important for predicting [Frequency] = 1 in a RandomForest model based on consumer attitude and perception data:\\n\\n{feature_importance_df.head(10).to_string(index=False)}\\n\\n.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939aad98-817c-4342-954b-0dad99614751",
   "metadata": {},
   "source": [
    "## ChatGPT Response\n",
    "Provide a final summary of both equity and diary drivers combined, brought to you by GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b78f3f7-e39b-440a-a9a1-ba9c0d618e11",
   "metadata": {},
   "source": [
    "#### Context\n",
    "Provide context to GPT to support its interpretation of the model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c19f3668-f090-44a4-9133-9f5d07369f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have results from a model aimed at helping marketers understand how to make people drink their brands every single week based on Diary (behavior) and Equity (attitudes/perceptions) data. The following prompt is structured as follows:\n",
      "- A summary of context about the question to be answered, meaning of variables, and an example output that can help guide the structure of the final response.\n",
      "- The results of the diary-specific random forest model that help explain what makes people drink every single week (weekly+).\n",
      "- A few key insights based on the Diary-specific random forest results.\n",
      "- The results of the equity-specific random forest model that help explain what makes people drink every single week (weekly+).\n",
      "- A few key insights based on the equity-specific random forest results.\n",
      "- Always structure the response with three sections split with the following headers: '#### Behavior Factors', '#### Equity Factors', '#### Recommendations'\n",
      "\n",
      "\n",
      "CONTEXT, DEFINITIONS, AND EXAMPLES: Below are important context, considerations, variable definitions, and a response example to consider prior to reviewing data and insights.\n",
      "- Where Frequency = 1, the user consumes every week. This is referred to as Weekly+.\n",
      "- While variable importance means the variable is meaningful, the % change in probability will be most interesting when referencing opportunities to size big opportunities.\n",
      "- The equity model uses variables describing users' 'behaviors', 'attitudes' and 'perceptions' about the brand.\n",
      "- Where imagery = 1, the user agrees that the brand has this imagery.\n",
      "- The attitude questions are the ones with columns ending in '_name' and are scaled answers, generally from something like -3 (I hate it) to +3 (I love it).\n",
      "- The behavior model uses variables from a consumer diary, where we get context around every single drink they record.\n",
      "- Consider merging related fields together into a single recommendation. Example, if there are multiple channels that are highly impactful, you could combine them into a single recommendation about channel.\n",
      "\n",
      "Here are short descriptions of what each feature/variable means:\n",
      "Attitude/Preferences (Equity/Imagery) Feature Definitions:\n",
      "- Familiarity_Name: A field containing the response from a 6-point-scale to the question 'How familiar are you with each of these brands?'\n",
      "- Cons_Name: A field containing the response from a 4-point-scale to the question 'How likely are you to consider choosing each of these brands the next time you drink [insert category]?' from 'It would be my first choice' to 'I would not consider it.'\n",
      "- Affinity_Name: A field containing the response from a 7-point-scale to the question 'How do you feel about each brand?'\n",
      "- Unique_Name: A field containing the response from a 3-point-scale to the question 'Is this brand worth more or less than it costs?'\n",
      "- MNeeds_Name: A field containing the response from a 7-point-scale to the prompt 'Drag each brand onto the scale to show how well each brand delivers the main things you need from a [insert category name].'\n",
      "- Dynamic_Name: A field containing the response from a 7-point-scale to the prompt 'Drag each brand onto the scale to show how much it sets trends.'\n",
      "- Price_Name: A field containing the response from a 7-point-scale to the prompt 'Drag each brand onto the scale to show how much you think it costs.'\n",
      "- Worth_Name: A field containing the response from a 7-point-scale to the prompt 'Drag each brand onto the scale to show how different it seems from other brands of [insert category].'\n",
      "- Encourages me to try new things: A 1 when the consumer says they agree with the statement: 'Encourages me to try new things.'\n",
      "- Is a youthful brand: A 1 when the consumer says they agree with the statement: 'Is a youthful brand.'\n",
      "- Is a brand for everyone: A 1 when the consumer says they agree with the statement: 'Is a brand for everyone.'\n",
      "- Has a flavor I enjoy: A 1 when the consumer says they agree with the statement: 'Has a flavor I enjoy.'\n",
      "- Shares my values: A 1 when the consumer says they agree with the statement: 'Shares my values.'\n",
      "- Offers quality I can trust: A 1 when the consumer says they agree with the statement: 'Offers quality I can trust.'\n",
      "- Cares about the environment: A 1 when the consumer says they agree with the statement: 'Cares about the environment.'\n",
      "- Is easy to find in stores: A 1 when the consumer says they agree with the statement: 'Is easy to find in stores.'\n",
      "- Has a unique taste: A 1 when the consumer says they agree with the statement: 'Has a unique taste.'\n",
      "- Gives me an energy boost: A 1 when the consumer says they agree with the statement: 'Gives me an energy boost.'\n",
      "- Goes well with food: A 1 when the consumer says they agree with the statement: 'Goes well with food.'\n",
      "- Brings me happiness: A 1 when the consumer says they agree with the statement: 'Brings me happiness.'\n",
      "- Is available in convenient packaging: A 1 when the consumer says they agree with the statement: 'Is available in convenient packaging.'\n",
      "- Makes moments special: A 1 when the consumer says they agree with the statement: 'Makes moments special.'\n",
      "- Has a refreshing taste: A 1 when the consumer says they agree with the statement: 'Has a refreshing taste.'\n",
      "- Helps keep me going: A 1 when the consumer says they agree with the statement: 'Helps keep me going.'\n",
      "- Has the right amount of calories: A 1 when the consumer says they agree with the statement: 'Has the right amount of calories.'\n",
      "- Gives me confidence to be myself: A 1 when the consumer says they agree with the statement: 'Gives me confidence to be myself.'\n",
      "Behavior (Diary) Feature Definitions:\n",
      "- DayPart_Name: The general day part (time of day) the respondent had their drink: Early morning (between 6am and 8am), Mid-Morning (between 8am and 11am), Midday (between 11am and 2pm), etc.\n",
      "- Where_Name: A feature identifying where the product was consumed.\n",
      "- Who_Group_HL: A feature identifying whether the person consumed the product alone, with others, etc.\n",
      "- Bought_Name: A feature identifying whether the person taking the survey bought the product they consumed or if someone else purchased it.\n",
      "- IC/FC-SS/MS: A calculated column that classifies user-reported drinks into combinations of future-consumption (larger containers than what they can consume in one sitting), immediate consumption (smaller containers ready to drink), single-serve (individual containers for immediate consumption), and multiserve (multiple containers sold together, like 12 pack of cans) based on reported purchase pack and reported container drank from size.\n",
      "- Channel: A higher-level purchase channel (and level 2 of the channel hierarchy) such as Supermarket/Hypermarket/Warehouse, Grocery Store, Convenience Store/Gas/Petrol Station, etc.\n",
      "- Reason_Energize: A 1 when the consumer says this is the reason for drinking the brand: Energize.\n",
      "- Reason_Celebrate: A 1 when the consumer says this is the reason for drinking the brand: Celebrate.\n",
      "- Reason_Stay: A 1 when the consumer says this is the reason for drinking the brand: Stay.\n",
      "- Reason_Rehydrate: A 1 when the consumer says this is the reason for drinking the brand: Rehydrate.\n",
      "- Reason_Cheer: A 1 when the consumer says this is the reason for drinking the brand: Cheer.\n",
      "- Reason_Close: A 1 when the consumer says this is the reason for drinking the brand: Close.\n",
      "- Reason_Cool: A 1 when the consumer says this is the reason for drinking the brand: Cool.\n",
      "- Reason_Nutritious: A 1 when the consumer says this is the reason for drinking the brand: Nutritious.\n",
      "- Reason_Focus: A 1 when the consumer says this is the reason for drinking the brand: Focus.\n",
      "- Reason_Complement: A 1 when the consumer says this is the reason for drinking the brand: Complement.\n",
      "- Reason_Confident: A 1 when the consumer says this is the reason for drinking the brand: Confident.\n",
      "- Reason_Taste: A 1 when the consumer says this is the reason for drinking the brand: Taste.\n",
      "- Reason_Reward: A 1 when the consumer says this is the reason for drinking the brand: Reward.\n",
      "- Reason_Restore: A 1 when the consumer says this is the reason for drinking the brand: Restore.\n",
      "- Reason_Performance: A 1 when the consumer says this is the reason for drinking the brand: Performance.\n",
      "- Reason_Other: A 1 when the consumer says this is the reason for drinking the brand: Other.\n",
      "- High-Level-Occasions: The key drinking occasions such as: Being Productive, Snacking, Eating, Active Leisure/Exercise, Relaxing, Routine Behaviors, Starting The Day, Socializing.\n",
      "Things in general to know about these products/categories:\n",
      "- Grocery, large store, club store, etc. may be more likely to sell multipacks, which have been shown to drive frequency of consumption when consumers can stock up and have product at home.\n",
      "- Intenders is a function of Affinity, Meets Needs, and Consideration. Intenders are people who we believe are highly likely of becoming weekly+.\n",
      "- This data is for Coca-Cola Original in the context of the Sparkling Soft Drinks category in the United States.\n",
      "- Users prefer answers like the following:\n",
      "- Familiarity: Being familiar with the brand significantly influences consumption frequency. Increasing familiarity with the drink can elevate the likelihood of weekly consumption by 13.8%—making this the most impactful variable.\n",
      "- vs\n",
      "- **Familiarity_Name_Drink most often**, - Change in predicted probability: +13.8%, - Building familiarity with your brand is crucial.\n",
      "\n",
      "- Including a strategic recommendation/guidance at the end will be appreciated by the marketer who wants to know what they should do.\n",
      "- Reference descriptions of variables (like Self-Purchase) over actual variable names (Bought_Name) when possible.\n",
      "\n",
      " DO NOT USE ANY OF THIS DATA FROM THIS EXAMPLE DIRECTLY IN YOUR ANSWER. ONLY USE THIS AS A GUIDE FOR HOW TO STRUCTURE YOUR RESPONSE:\n",
      "BEGINNING OF EXAMPLE:\n",
      "    To enhance the frequency of consumption for Coca-Cola Original within the Sparkling Soft Drinks category, here are the critical features that significantly influence weekly consumption, along with their respective impacts on the predicted probability of frequency.\n",
      "\n",
      "        ### Key Drivers for Increasing Frequency of Consumption:\n",
      "        \n",
      "        1. **Familiarity with the Brand**  \n",
      "           Increasing familiarity can boost likelihood of weekly consumption by 13.8%. Marketers should focus on improving brand recognition and recall to drive higher engagement.\n",
      "        \n",
      "        2. **Affinity Towards the Brand**  \n",
      "           Positive feelings towards the brand contribute an increase of 7.4% in weekly consumption likelihood. Implementing campaigns that foster emotional connections can be beneficial.\n",
      "        \n",
      "        3. **Intenders Segment**  \n",
      "           Targeting consumers who are likely to become weekly consumers can raise probabilities by 5.8%. Marketers should identify and engage these potential customers proactively.\n",
      "        \n",
      "        4. **Brand Preference**  \n",
      "           When consumers indicate the brand would be their first choice, it can raise weekly consumption likelihood by 5.4%. Strategies focusing on making the brand a top-of-mind option are essential.\n",
      "        \n",
      "        5. **Meeting Consumer Needs**  \n",
      "           Highlighting how well Coca-Cola meets consumer needs can increase frequency by 4.8%. Marketers should align product messaging with key consumer requirements.\n",
      "        \n",
      "        ### Behavioral Insights:\n",
      "        \n",
      "        1. **Self-Purchase**  \n",
      "           Encouraging consumers to buy Coca-Cola themselves can increase weekly consumption likelihood by 5.0%. Promotions and incentives for self-purchase should be emphasized.\n",
      "        \n",
      "        2. **Consumption at Home**  \n",
      "           Positioning Coca-Cola as a staple at home can boost frequency by 2.9%. Retail strategies focused on home consumption occasions, like multi-pack offers, would be effective.\n",
      "        \n",
      "        3. **Independent Stores**  \n",
      "           Ensuring availability at non-chain grocery stores can lead to a 2.1% increase in frequency. Building relationships with these retailers might enhance accessibility.\n",
      "        \n",
      "        4. **Single-Serve Options**  \n",
      "           Offering single-serve packaging can increase chances of weekly consumption by 1.6%. This can cater to consumers looking for convenient drinking options.\n",
      "        \n",
      "        5. **Eating Occasions**  \n",
      "           Associating the drink with meals can enhance frequency by 0.9%. Marketing strategies should leverage mealtime consumption opportunities.\n",
      "        \n",
      "        ### Recommendations:\n",
      "        - Focus on building brand familiarity through targeted advertising and community engagement.\n",
      "        - Develop campaigns that emphasize emotional connections and the unique qualities of Coca-Cola.\n",
      "        - Use promotions to encourage self-purchase and availability in grocery stores, especially independent ones.\n",
      "        - Position Coca-Cola effectively for home consumption and highlight its refreshing taste and energizing attributes. \n",
      "        \n",
      "        By strategically implementing these insights, there is potential for significant growth in the frequency of Coca-Cola consumption among consumers.\n",
      "        END OF EXAMPLE\n",
      "        \n",
      "\n",
      "Please summarize the following results for a marketer trying to grow their brand's frequency. Format all percentages with only 1 decimal point. Remove Asterisks/Bolding references in final response.\n",
      "\n",
      "\n",
      "\n",
      " DATA AND INSIGHTS TO BE USED IN YOUR RESPONSE:\n",
      "\n",
      "The following are the top features most important for predicting [Frequency] = 1 in a RandomForest model based on diary (consumer behavior) data:\n",
      "\n",
      "                                               Feature  Importance  Change in Predicted Probability (%)\n",
      "                        Bought_Name_I bought it myself    0.019617                             5.147070\n",
      "                                    Where_Name_At Home    0.020199                             3.708645\n",
      "Channel_Grocery store (not a chain)/ Independent store    0.014928                             1.982417\n",
      "     Channel_Supermarket/ Hypermarket/ warehouse store    0.020755                             1.866099\n",
      "                                     IC/FC-SS/MS_IC-SS    0.024729                             1.635552\n",
      "            DayPart_Name_Midday (between 11am and 2pm)    0.030083                             0.912524\n",
      "                           High-Level-Occasions_Eating    0.031560                             0.708786\n",
      "                                    Who_Group_HL_Alone    0.021841                             0.600023\n",
      "      DayPart_Name_Early Morning (between 6am and 8am)    0.007458                             0.469842\n",
      "                 High-Level-Occasions_Starting The Day    0.008069                             0.350703\n",
      "\n",
      ".\n",
      "\n",
      "The following are insights from the behavior (diary) drivers of Weekly+:\n",
      "\n",
      "Feature: Bought_Name_I bought it myself\n",
      "Change in predicted probability: +5.15%\n",
      "For example, moving the perception of 'Bought_Name_I bought it myself' from a low level to a high level can increase the likelihood of frequent usage (Frequency = 1) by 5.15%.\n",
      "Feature: Where_Name_At Home\n",
      "Change in predicted probability: +3.71%\n",
      "For example, moving the perception of 'Where_Name_At Home' from a low level to a high level can increase the likelihood of frequent usage (Frequency = 1) by 3.71%.\n",
      "Feature: Channel_Grocery store (not a chain)/ Independent store\n",
      "Change in predicted probability: +1.98%\n",
      "For example, moving the perception of 'Channel_Grocery store (not a chain)/ Independent store' from a low level to a high level can increase the likelihood of frequent usage (Frequency = 1) by 1.98%.\n",
      "Feature: Channel_Supermarket/ Hypermarket/ warehouse store\n",
      "Change in predicted probability: +1.87%\n",
      "For example, moving the perception of 'Channel_Supermarket/ Hypermarket/ warehouse store' from a low level to a high level can increase the likelihood of frequent usage (Frequency = 1) by 1.87%.\n",
      "Feature: IC/FC-SS/MS_IC-SS\n",
      "Change in predicted probability: +1.64%\n",
      "For example, moving the perception of 'IC/FC-SS/MS_IC-SS' from a low level to a high level can increase the likelihood of frequent usage (Frequency = 1) by 1.64%.\n",
      "Feature: DayPart_Name_Midday (between 11am and 2pm)\n",
      "Change in predicted probability: +0.91%\n",
      "For example, moving the perception of 'DayPart_Name_Midday (between 11am and 2pm)' from a low level to a high level can increase the likelihood of frequent usage (Frequency = 1) by 0.91%.\n",
      "Feature: High-Level-Occasions_Eating\n",
      "Change in predicted probability: +0.71%\n",
      "For example, moving the perception of 'High-Level-Occasions_Eating' from a low level to a high level can increase the likelihood of frequent usage (Frequency = 1) by 0.71%.\n",
      "Feature: Who_Group_HL_Alone\n",
      "Change in predicted probability: +0.60%\n",
      "For example, moving the perception of 'Who_Group_HL_Alone' from a low level to a high level can increase the likelihood of frequent usage (Frequency = 1) by 0.60%.\n",
      "Feature: DayPart_Name_Early Morning (between 6am and 8am)\n",
      "Change in predicted probability: +0.47%\n",
      "For example, moving the perception of 'DayPart_Name_Early Morning (between 6am and 8am)' from a low level to a high level can increase the likelihood of frequent usage (Frequency = 1) by 0.47%.\n",
      "Feature: High-Level-Occasions_Starting The Day\n",
      "Change in predicted probability: +0.35%\n",
      "For example, moving the perception of 'High-Level-Occasions_Starting The Day' from a low level to a high level can increase the likelihood of frequent usage (Frequency = 1) by 0.35%.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The following are the top features most important for predicting [Frequency] = 1 in a RandomForest model based on consumer attitude and perception data:\n",
      "\n",
      "                              Feature  Importance  Change in Predicted Probability (%)\n",
      "    Familiarity_Name_Drink most often    0.051077                            11.047639\n",
      "           Affinity_Name_+3 I love it    0.039802                             8.804520\n",
      "               Cons_Segment_Intenders    0.041640                             8.150561\n",
      "Cons_Name_It would be my first choice    0.030347                             5.481609\n",
      "  MNeeds_Name_7 Meets needs very well    0.027698                             4.016622\n",
      "                        Unique_Name_6    0.015950                             2.145606\n",
      "                         Price_Name_3    0.005104                             1.743643\n",
      "                  Brings me happiness    0.037265                             1.312017\n",
      "                  Helps keep me going    0.023415                             1.310435\n",
      "                 Has a flavor I enjoy    0.023649                             1.155707\n",
      "\n",
      ".\n",
      "\n",
      "The following are insights from the equity/imagery drivers of Weekly+:\n",
      "\n",
      "Feature: Familiarity_Name_Drink most often\n",
      "Change in predicted probability: +11.05%\n",
      "For example, moving the perception of 'Familiarity_Name_Drink most often' from a low level to a high level can increase the likelihood of frequent usage (Frequency = 1) by 11.05%.\n",
      "Feature: Affinity_Name_+3 I love it\n",
      "Change in predicted probability: +8.80%\n",
      "For example, moving the perception of 'Affinity_Name_+3 I love it' from a low level to a high level can increase the likelihood of frequent usage (Frequency = 1) by 8.80%.\n",
      "Feature: Cons_Segment_Intenders\n",
      "Change in predicted probability: +8.15%\n",
      "For example, moving the perception of 'Cons_Segment_Intenders' from a low level to a high level can increase the likelihood of frequent usage (Frequency = 1) by 8.15%.\n",
      "Feature: Cons_Name_It would be my first choice\n",
      "Change in predicted probability: +5.48%\n",
      "For example, moving the perception of 'Cons_Name_It would be my first choice' from a low level to a high level can increase the likelihood of frequent usage (Frequency = 1) by 5.48%.\n",
      "Feature: MNeeds_Name_7 Meets needs very well\n",
      "Change in predicted probability: +4.02%\n",
      "For example, moving the perception of 'MNeeds_Name_7 Meets needs very well' from a low level to a high level can increase the likelihood of frequent usage (Frequency = 1) by 4.02%.\n",
      "Feature: Unique_Name_6\n",
      "Change in predicted probability: +2.15%\n",
      "For example, moving the perception of 'Unique_Name_6' from a low level to a high level can increase the likelihood of frequent usage (Frequency = 1) by 2.15%.\n",
      "Feature: Price_Name_3\n",
      "Change in predicted probability: +1.74%\n",
      "For example, moving the perception of 'Price_Name_3' from a low level to a high level can increase the likelihood of frequent usage (Frequency = 1) by 1.74%.\n",
      "Feature: Brings me happiness\n",
      "Change in predicted probability: +1.31%\n",
      "For example, moving the perception of 'Brings me happiness' from a low level to a high level can increase the likelihood of frequent usage (Frequency = 1) by 1.31%.\n",
      "Feature: Helps keep me going\n",
      "Change in predicted probability: +1.31%\n",
      "For example, moving the perception of 'Helps keep me going' from a low level to a high level can increase the likelihood of frequent usage (Frequency = 1) by 1.31%.\n",
      "Feature: Has a flavor I enjoy\n",
      "Change in predicted probability: +1.16%\n",
      "For example, moving the perception of 'Has a flavor I enjoy' from a low level to a high level can increase the likelihood of frequent usage (Frequency = 1) by 1.16%.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Descript the structure of the prompt\n",
    "prompt_structure = (\n",
    "    \"I have results from a model aimed at helping marketers understand how to make people drink their brands every single week based on Diary (behavior) and Equity (attitudes/perceptions) data. The following prompt is structured as follows:\"\n",
    "    \"\\n- A summary of context about the question to be answered, meaning of variables, and an example output that can help guide the structure of the final response.\"\n",
    "    \"\\n- The results of the diary-specific random forest model that help explain what makes people drink every single week (weekly+).\"\n",
    "    \"\\n- A few key insights based on the Diary-specific random forest results.\"\n",
    "    \"\\n- The results of the equity-specific random forest model that help explain what makes people drink every single week (weekly+).\"\n",
    "    \"\\n- A few key insights based on the equity-specific random forest results.\"\n",
    "    \"\\n- Always structure the response with three sections split with the following headers: '#### Behavior Factors', '#### Equity Factors', '#### Recommendations'\"\n",
    "    \"\\n\")\n",
    "\n",
    "\n",
    "# Create a context string for ChatGPT\n",
    "context = (\n",
    "    \"CONTEXT, DEFINITIONS, AND EXAMPLES: Below are important context, considerations, variable definitions, and a response example to consider prior to reviewing data and insights.\"\n",
    "    \"\\n- Where Frequency = 1, the user consumes every week. This is referred to as Weekly+.\"\n",
    "    \"\\n- While variable importance means the variable is meaningful, the % change in probability will be most interesting when referencing opportunities to size big opportunities.\"\n",
    "    \"\\n- The equity model uses variables describing users' 'behaviors', 'attitudes' and 'perceptions' about the brand.\"\n",
    "    \"\\n- Where imagery = 1, the user agrees that the brand has this imagery.\"\n",
    "    \"\\n- The attitude questions are the ones with columns ending in '_name' and are scaled answers, generally from something like -3 (I hate it) to +3 (I love it).\"\n",
    "    \"\\n- The behavior model uses variables from a consumer diary, where we get context around every single drink they record.\"\n",
    "    \"\\n- Consider merging related fields together into a single recommendation. Example, if there are multiple channels that are highly impactful, you could combine them into a single recommendation about channel.\"\n",
    "    \"\\n\\nHere are short descriptions of what each feature/variable means:\"\n",
    "    \n",
    "    \"\\nAttitude/Preferences (Equity/Imagery) Feature Definitions:\"\n",
    "    \"\\n- Familiarity_Name: A field containing the response from a 6-point-scale to the question 'How familiar are you with each of these brands?'\"\n",
    "    \"\\n- Cons_Name: A field containing the response from a 4-point-scale to the question 'How likely are you to consider choosing each of these brands the next time you drink [insert category]?' from 'It would be my first choice' to 'I would not consider it.'\"\n",
    "    \"\\n- Affinity_Name: A field containing the response from a 7-point-scale to the question 'How do you feel about each brand?'\"\n",
    "    \"\\n- Unique_Name: A field containing the response from a 3-point-scale to the question 'Is this brand worth more or less than it costs?'\"\n",
    "    \"\\n- MNeeds_Name: A field containing the response from a 7-point-scale to the prompt 'Drag each brand onto the scale to show how well each brand delivers the main things you need from a [insert category name].'\"\n",
    "    \"\\n- Dynamic_Name: A field containing the response from a 7-point-scale to the prompt 'Drag each brand onto the scale to show how much it sets trends.'\"\n",
    "    \"\\n- Price_Name: A field containing the response from a 7-point-scale to the prompt 'Drag each brand onto the scale to show how much you think it costs.'\"\n",
    "    \"\\n- Worth_Name: A field containing the response from a 7-point-scale to the prompt 'Drag each brand onto the scale to show how different it seems from other brands of [insert category].'\"\n",
    "    \"\\n- Encourages me to try new things: A 1 when the consumer says they agree with the statement: 'Encourages me to try new things.'\"\n",
    "    \"\\n- Is a youthful brand: A 1 when the consumer says they agree with the statement: 'Is a youthful brand.'\"\n",
    "    \"\\n- Is a brand for everyone: A 1 when the consumer says they agree with the statement: 'Is a brand for everyone.'\"\n",
    "    \"\\n- Has a flavor I enjoy: A 1 when the consumer says they agree with the statement: 'Has a flavor I enjoy.'\"\n",
    "    \"\\n- Shares my values: A 1 when the consumer says they agree with the statement: 'Shares my values.'\"\n",
    "    \"\\n- Offers quality I can trust: A 1 when the consumer says they agree with the statement: 'Offers quality I can trust.'\"\n",
    "    \"\\n- Cares about the environment: A 1 when the consumer says they agree with the statement: 'Cares about the environment.'\"\n",
    "    \"\\n- Is easy to find in stores: A 1 when the consumer says they agree with the statement: 'Is easy to find in stores.'\"\n",
    "    \"\\n- Has a unique taste: A 1 when the consumer says they agree with the statement: 'Has a unique taste.'\"\n",
    "    \"\\n- Gives me an energy boost: A 1 when the consumer says they agree with the statement: 'Gives me an energy boost.'\"\n",
    "    \"\\n- Goes well with food: A 1 when the consumer says they agree with the statement: 'Goes well with food.'\"\n",
    "    \"\\n- Brings me happiness: A 1 when the consumer says they agree with the statement: 'Brings me happiness.'\"\n",
    "    \"\\n- Is available in convenient packaging: A 1 when the consumer says they agree with the statement: 'Is available in convenient packaging.'\"\n",
    "    \"\\n- Makes moments special: A 1 when the consumer says they agree with the statement: 'Makes moments special.'\"\n",
    "    \"\\n- Has a refreshing taste: A 1 when the consumer says they agree with the statement: 'Has a refreshing taste.'\"\n",
    "    \"\\n- Helps keep me going: A 1 when the consumer says they agree with the statement: 'Helps keep me going.'\"\n",
    "    \"\\n- Has the right amount of calories: A 1 when the consumer says they agree with the statement: 'Has the right amount of calories.'\"\n",
    "    \"\\n- Gives me confidence to be myself: A 1 when the consumer says they agree with the statement: 'Gives me confidence to be myself.'\"\n",
    "    \n",
    "    \"\\nBehavior (Diary) Feature Definitions:\"\n",
    "    \"\\n- DayPart_Name: The general day part (time of day) the respondent had their drink: Early morning (between 6am and 8am), Mid-Morning (between 8am and 11am), Midday (between 11am and 2pm), etc.\"\n",
    "    \"\\n- Where_Name: A feature identifying where the product was consumed.\"\n",
    "    \"\\n- Who_Group_HL: A feature identifying whether the person consumed the product alone, with others, etc.\"\n",
    "    \"\\n- Bought_Name: A feature identifying whether the person taking the survey bought the product they consumed or if someone else purchased it.\"\n",
    "    \"\\n- IC/FC-SS/MS: A calculated column that classifies user-reported drinks into combinations of future-consumption (larger containers than what they can consume in one sitting), immediate consumption (smaller containers ready to drink), single-serve (individual containers for immediate consumption), and multiserve (multiple containers sold together, like 12 pack of cans) based on reported purchase pack and reported container drank from size.\"\n",
    "    \"\\n- Channel: A higher-level purchase channel (and level 2 of the channel hierarchy) such as Supermarket/Hypermarket/Warehouse, Grocery Store, Convenience Store/Gas/Petrol Station, etc.\"\n",
    "    \"\\n- Reason_Energize: A 1 when the consumer says this is the reason for drinking the brand: Energize.\"\n",
    "    \"\\n- Reason_Celebrate: A 1 when the consumer says this is the reason for drinking the brand: Celebrate.\"\n",
    "    \"\\n- Reason_Stay: A 1 when the consumer says this is the reason for drinking the brand: Stay.\"\n",
    "    \"\\n- Reason_Rehydrate: A 1 when the consumer says this is the reason for drinking the brand: Rehydrate.\"\n",
    "    \"\\n- Reason_Cheer: A 1 when the consumer says this is the reason for drinking the brand: Cheer.\"\n",
    "    \"\\n- Reason_Close: A 1 when the consumer says this is the reason for drinking the brand: Close.\"\n",
    "    \"\\n- Reason_Cool: A 1 when the consumer says this is the reason for drinking the brand: Cool.\"\n",
    "    \"\\n- Reason_Nutritious: A 1 when the consumer says this is the reason for drinking the brand: Nutritious.\"\n",
    "    \"\\n- Reason_Focus: A 1 when the consumer says this is the reason for drinking the brand: Focus.\"\n",
    "    \"\\n- Reason_Complement: A 1 when the consumer says this is the reason for drinking the brand: Complement.\"\n",
    "    \"\\n- Reason_Confident: A 1 when the consumer says this is the reason for drinking the brand: Confident.\"\n",
    "    \"\\n- Reason_Taste: A 1 when the consumer says this is the reason for drinking the brand: Taste.\"\n",
    "    \"\\n- Reason_Reward: A 1 when the consumer says this is the reason for drinking the brand: Reward.\"\n",
    "    \"\\n- Reason_Restore: A 1 when the consumer says this is the reason for drinking the brand: Restore.\"\n",
    "    \"\\n- Reason_Performance: A 1 when the consumer says this is the reason for drinking the brand: Performance.\"\n",
    "    \"\\n- Reason_Other: A 1 when the consumer says this is the reason for drinking the brand: Other.\"\n",
    "    \"\\n- High-Level-Occasions: The key drinking occasions such as: Being Productive, Snacking, Eating, Active Leisure/Exercise, Relaxing, Routine Behaviors, Starting The Day, Socializing.\"\n",
    "\n",
    "    \"\\nThings in general to know about these products/categories:\"\n",
    "    \"\\n- Grocery, large store, club store, etc. may be more likely to sell multipacks, which have been shown to drive frequency of consumption when consumers can stock up and have product at home.\"\n",
    "    \"\\n- Intenders is a function of Affinity, Meets Needs, and Consideration. Intenders are people who we believe are highly likely of becoming weekly+.\"\n",
    "    \"\\n- This data is for Coca-Cola Original in the context of the Sparkling Soft Drinks category in the United States.\"\n",
    "    \"\\n- Users prefer answers like the following:\"\n",
    "    \"\\n- Familiarity: Being familiar with the brand significantly influences consumption frequency. Increasing familiarity with the drink can elevate the likelihood of weekly consumption by 13.8%—making this the most impactful variable.\"\n",
    "    \"\\n- vs\"\n",
    "    \"\\n- **Familiarity_Name_Drink most often**, - Change in predicted probability: +13.8%, - Building familiarity with your brand is crucial.\"\n",
    "    \"\\n\\n- Including a strategic recommendation/guidance at the end will be appreciated by the marketer who wants to know what they should do.\"\n",
    "    \"\\n- Reference descriptions of variables (like Self-Purchase) over actual variable names (Bought_Name) when possible.\"\n",
    "\n",
    "    \"\\n\\n DO NOT USE ANY OF THIS DATA FROM THIS EXAMPLE DIRECTLY IN YOUR ANSWER. ONLY USE THIS AS A GUIDE FOR HOW TO STRUCTURE YOUR RESPONSE:\"\n",
    "    \"\\n\"\n",
    "    \"\"\"BEGINNING OF EXAMPLE:\n",
    "    To enhance the frequency of consumption for Coca-Cola Original within the Sparkling Soft Drinks category, here are the critical features that significantly influence weekly consumption, along with their respective impacts on the predicted probability of frequency.\n",
    "\n",
    "        ### Key Drivers for Increasing Frequency of Consumption:\n",
    "        \n",
    "        1. **Familiarity with the Brand**  \n",
    "           Increasing familiarity can boost likelihood of weekly consumption by 13.8%. Marketers should focus on improving brand recognition and recall to drive higher engagement.\n",
    "        \n",
    "        2. **Affinity Towards the Brand**  \n",
    "           Positive feelings towards the brand contribute an increase of 7.4% in weekly consumption likelihood. Implementing campaigns that foster emotional connections can be beneficial.\n",
    "        \n",
    "        3. **Intenders Segment**  \n",
    "           Targeting consumers who are likely to become weekly consumers can raise probabilities by 5.8%. Marketers should identify and engage these potential customers proactively.\n",
    "        \n",
    "        4. **Brand Preference**  \n",
    "           When consumers indicate the brand would be their first choice, it can raise weekly consumption likelihood by 5.4%. Strategies focusing on making the brand a top-of-mind option are essential.\n",
    "        \n",
    "        5. **Meeting Consumer Needs**  \n",
    "           Highlighting how well Coca-Cola meets consumer needs can increase frequency by 4.8%. Marketers should align product messaging with key consumer requirements.\n",
    "        \n",
    "        ### Behavioral Insights:\n",
    "        \n",
    "        1. **Self-Purchase**  \n",
    "           Encouraging consumers to buy Coca-Cola themselves can increase weekly consumption likelihood by 5.0%. Promotions and incentives for self-purchase should be emphasized.\n",
    "        \n",
    "        2. **Consumption at Home**  \n",
    "           Positioning Coca-Cola as a staple at home can boost frequency by 2.9%. Retail strategies focused on home consumption occasions, like multi-pack offers, would be effective.\n",
    "        \n",
    "        3. **Independent Stores**  \n",
    "           Ensuring availability at non-chain grocery stores can lead to a 2.1% increase in frequency. Building relationships with these retailers might enhance accessibility.\n",
    "        \n",
    "        4. **Single-Serve Options**  \n",
    "           Offering single-serve packaging can increase chances of weekly consumption by 1.6%. This can cater to consumers looking for convenient drinking options.\n",
    "        \n",
    "        5. **Eating Occasions**  \n",
    "           Associating the drink with meals can enhance frequency by 0.9%. Marketing strategies should leverage mealtime consumption opportunities.\n",
    "        \n",
    "        ### Recommendations:\n",
    "        - Focus on building brand familiarity through targeted advertising and community engagement.\n",
    "        - Develop campaigns that emphasize emotional connections and the unique qualities of Coca-Cola.\n",
    "        - Use promotions to encourage self-purchase and availability in grocery stores, especially independent ones.\n",
    "        - Position Coca-Cola effectively for home consumption and highlight its refreshing taste and energizing attributes. \n",
    "        \n",
    "        By strategically implementing these insights, there is potential for significant growth in the frequency of Coca-Cola consumption among consumers.\n",
    "        END OF EXAMPLE\n",
    "        \"\"\"\n",
    "    \"\\n\\nPlease summarize the following results for a marketer trying to grow their brand's frequency. Format all percentages with only 1 decimal point. Remove Asterisks/Bolding references in final response.\"\n",
    "    \"\\n\\n\\n\\n DATA AND INSIGHTS TO BE USED IN YOUR RESPONSE:\"\n",
    "\n",
    ")\n",
    "prompt = f\"{prompt_structure}\\n\\n{context}\\n\\n{diaryprompt}\\n\\n{diary_insight}\\n\\n{equityprompt}\\n\\n{equity_insight}\\n\\n\"\n",
    "\n",
    "print(prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ac8546-f1f4-4019-87d0-548ac1ce3e85",
   "metadata": {},
   "source": [
    "#### Final qualitative review from ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2cd5b1d1-85bb-444f-b777-13f14234e2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Behavior Factors\n",
      "\n",
      "The following variables significantly increase the likelihood of weekly consumption of the brand:\n",
      "\n",
      "1. **Self-Purchase**\n",
      "   When buyers purchase the product themselves, the probability of weekly consumption increases by 5.1%.\n",
      "\n",
      "2. **Consumption at Home**\n",
      "   When the product is consumed at home, the likelihood of weekly consumption rises by 3.7%.\n",
      "\n",
      "3. **Independent Store Availability**\n",
      "   The availability of the product at non-chain, independent stores contributes to a 2.0% increase in the likelihood of weekly consumption.\n",
      "\n",
      "4. **Supermarket/Hypermarket/Warehouse Store Availability**\n",
      "   The availability of the product at supermarkets, hypermarkets, and warehouse stores can increase the probability of weekly consumption by 1.9%.\n",
      "\n",
      "5. **Immediate Consumption Single-Serve Products (IC-SS)**\n",
      "   Providing users with immediate consumption, single-serve options can increase the likelihood of weekly consumption by 1.6%.\n",
      "\n",
      "6. **Midday Consumption (between 11am and 2pm)**\n",
      "   When the product is consumed midday, the likelihood of weekly consumption increases by 0.9%.\n",
      "\n",
      "7. **Eating Occasions**\n",
      "   Consuming the product while eating can increase the likelihood of weekly consumption by 0.7%.\n",
      "\n",
      "8. **Alone Consumption**\n",
      "   Consuming the product alone can increase the likelihood of weekly consumption by 0.6%.\n",
      "\n",
      "9. **Early Morning Consumption (between 6am and 8am)**\n",
      "   Consuming the product early in the morning can increase the likelihood of weekly consumption by 0.5%.\n",
      "\n",
      "10. **Starting the Day Consumption**\n",
      "    Consuming the product as a part of starting one's day can increase the likelihood of weekly consumption by 0.4%.\n",
      "\n",
      "#### Equity Factors\n",
      "\n",
      "The following variables significantly increase the likelihood of weekly consumption of the brand:\n",
      "\n",
      "1. **Familiarity**\n",
      "   When users are most familiar with the product, the likelihood of weekly consumption increases by 11.0%.\n",
      "\n",
      "2. **Affinity**\n",
      "   Users who love the brand contribute an 8.8% increase to the likelihood of weekly consumption.\n",
      "\n",
      "3. **Target Intenders Segment**\n",
      "   Targeting intenders -- those likely to become weekly consumers -- can increase weekly consumption likelihood by 8.2%.\n",
      "\n",
      "4. **Brand Preference (First Choice)**\n",
      "   When the brand is a consumer's first choice, it can elevate weekly consumption likelihood by 5.5%.\n",
      "\n",
      "5. **Meeting Needs**\n",
      "   Believing the brand meets their needs very well can increase the likelihood of weekly consumption by 4.0%.\n",
      "\n",
      "6. **Uniqueness**\n",
      "   Perceiving the brand as unique can increase the likelihood of weekly consumption by 2.1%.\n",
      "\n",
      "7. **Price Perception**\n",
      "   When consumers believe the price is reasonable (Price_Name_3), the likelihood of weekly consumption increases by 1.7%.\n",
      "\n",
      "8. **Happiness**\n",
      "   The perception that the brand brings happiness can increase the likelihood of weekly consumption by 1.3%.\n",
      "\n",
      "9. **Energy**\n",
      "   Believing that the brand helps keep the consumer going can increase the likelihood of weekly consumption by 1.3%.\n",
      "\n",
      "10. **Flavor Enjoyment**\n",
      "    Enjoying the taste of the brand can increase the likelihood of weekly consumption by 1.2%.\n",
      "\n",
      "#### Recommendations\n",
      "\n",
      "With these insights, the following strategic recommendations are offered:\n",
      "\n",
      "- Encourage consumers to purchase the product themselves and consume it at home.\n",
      "- Ensure product availability in non-chain grocery stores, supermarkets, hypermarkets, and warehouse stores.\n",
      "- Offer immediate consumption, single-serve options to cater to a variety of consumption occasions.\n",
      "- Highlight the brand's role in making everyday activities, like meals and starting the day, more enjoyable.\n",
      "- Build familiarity and love for the brand among consumers.\n",
      "- Engage consumers who are predisposed to becoming weekly consumers.\n",
      "- Show how well the brand meets consumer needs and point out its uniqueness.\n",
      "- Reinforce the value of the product for its price.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare the final prompt to send to ChatGPT\n",
    "prompt = f\"{prompt_structure}\\n\\n{context}\\n\\n{diaryprompt}\\n\\n{diary_insight}\\n\\n{equityprompt}\\n\\n{equity_insight}\\n\\n\"\n",
    "\n",
    "# Chat completion request payload\n",
    "irequest = {\n",
    "    \"temperature\": 1,\n",
    "    \"top_p\": 1,\n",
    "    \"max_tokens\": 1000,\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Convert request to JSON\n",
    "data = json.dumps(irequest)\n",
    "\n",
    "# Define request URL and headers\n",
    "url = f\"https://apim-emt-aip-prod-01.azure-api.net/openai/deployments/{deployment}/chat/completions?api-version={apiversion}\"\n",
    "hdr = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Ocp-Apim-Subscription-Key': api_key\n",
    "}\n",
    "\n",
    "# Make the request\n",
    "try:\n",
    "    req = urllib.request.Request(url, headers=hdr, data=bytes(data.encode(\"utf-8\")))\n",
    "    req.get_method = lambda: 'POST'\n",
    "    response = urllib.request.urlopen(req)\n",
    "    \n",
    "    # Parse the response and extract content\n",
    "    response_body = response.read()\n",
    "    response_json = json.loads(response_body.decode('utf-8'))\n",
    "    \n",
    "    # Extract and print only the content of the response\n",
    "    response_content = response_json['choices'][0]['message']['content']\n",
    "    print(response_content)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e90d4a-8289-457b-b1c7-dfec0d231422",
   "metadata": {},
   "source": [
    "## Final Output\n",
    "Output Generation via PowerPoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a025c4c-9817-4bf8-85c9-c8e48e150bd8",
   "metadata": {},
   "source": [
    "#### Extract the correct rows from GPT response and store them into variables for use in PowerPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "de48bff8-403f-4965-895e-785fb7575a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With these insights, the following strategic recommendations are offered:\n",
      "- Encourage consumers to purchase the product themselves and consume it at home.\n",
      "- Ensure product availability in non-chain grocery stores, supermarkets, hypermarkets, and warehouse stores.\n",
      "- Offer immediate consumption, single-serve options to cater to a variety of consumption occasions.\n",
      "- Highlight the brand's role in making everyday activities, like meals and starting the day, more enjoyable.\n",
      "- Build familiarity and love for the brand among consumers.\n",
      "- Engage consumers who are predisposed to becoming weekly consumers.\n",
      "- Show how well the brand meets consumer needs and point out its uniqueness.\n",
      "- Reinforce the value of the product for its price.\n"
     ]
    }
   ],
   "source": [
    "# Function to extract specific sections from the content\n",
    "def extract_sections(content):\n",
    "    # Split the content by lines\n",
    "    lines = content.splitlines()\n",
    "    \n",
    "    # Initialize empty strings for each section\n",
    "    behavior_factors = []\n",
    "    equity_factors = []\n",
    "    recommendations = []\n",
    "    \n",
    "    # Initialize flags to track the current section\n",
    "    in_behavior = False\n",
    "    in_equity = False\n",
    "    in_recommendations = False\n",
    "    \n",
    "    # Loop through each line and categorize it into the appropriate section\n",
    "    for line in lines:\n",
    "        line = line.strip()  # Remove any extra spaces\n",
    "        \n",
    "        # Detect section headers and toggle flags\n",
    "        if \"#### Behavior Factors\" in line:\n",
    "            in_behavior = True\n",
    "            in_equity = False\n",
    "            in_recommendations = False\n",
    "        elif \"#### Equity Factors\" in line:\n",
    "            in_behavior = False\n",
    "            in_equity = True\n",
    "            in_recommendations = False\n",
    "        elif \"#### Recommendations\" in line:\n",
    "            in_behavior = False\n",
    "            in_equity = False\n",
    "            in_recommendations = True\n",
    "        else:\n",
    "            # Append the line to the appropriate section\n",
    "            if in_behavior:\n",
    "                behavior_factors.append(line)\n",
    "            elif in_equity:\n",
    "                equity_factors.append(line)\n",
    "            elif in_recommendations:\n",
    "                recommendations.append(line)\n",
    "    \n",
    "    # Join the lists back into strings\n",
    "    consumption_drivers_text = \"\\n\".join([line for line in behavior_factors if line]).strip()\n",
    "    equity_drivers_text = \"\\n\".join([line for line in equity_factors if line]).strip()\n",
    "    recommendations_text = \"\\n\".join([line for line in recommendations if line]).strip()\n",
    "    \n",
    "    return consumption_drivers_text, equity_drivers_text, recommendations_text\n",
    "\n",
    "# Extract the text from the response content\n",
    "consumption_drivers_text, equity_drivers_text, recommendations_text = extract_sections(response_content)\n",
    "\n",
    "# Print the results to check\n",
    "#print(consumption_drivers_text)\n",
    "#print(equity_drivers_text)\n",
    "print(recommendations_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8a8e4f-e47e-4a48-8f19-9d38e4391d96",
   "metadata": {},
   "source": [
    "#### Adjust the length of each driver text so that it fits in the text box"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09833465-a98c-4b3c-9f97-8bdfe3fa2e82",
   "metadata": {},
   "source": [
    "Recommendations Text Length Adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "624a0928-e7de-4e66-a350-b26c3ccfd128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With these insights, the following strategic recommendations are offered:\n",
      "- Encourage consumers to purchase the product themselves and consume it at home.\n",
      "- Ensure product availability in non-chain grocery stores, supermarkets, hypermarkets, and warehouse stores.\n",
      "- Highlight the brand's role in making everyday activities, like meals and starting the day, more enjoyable.\n",
      "- Build familiarity and love for the brand among consumers.\n",
      "- Engage consumers who are predisposed to becoming weekly consumers.\n"
     ]
    }
   ],
   "source": [
    "new_prompt = f\"Reduce the number of lines in the following string to only include 5 recommendations. Accomplish this by reducing the number of recommendations, starting with the last one:\\n{recommendations_text}\"\n",
    "\n",
    "# Chat completion request payload\n",
    "irequest = {\n",
    "    \"temperature\": 1,\n",
    "    \"top_p\": 1,\n",
    "    \"max_tokens\": 1000,\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": new_prompt}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Convert request to JSON\n",
    "data = json.dumps(irequest)\n",
    "\n",
    "# Define request URL and headers\n",
    "url = f\"https://apim-emt-aip-prod-01.azure-api.net/openai/deployments/{deployment}/chat/completions?api-version={apiversion}\"\n",
    "hdr = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Ocp-Apim-Subscription-Key': api_key\n",
    "}\n",
    "\n",
    "# Make the request\n",
    "try:\n",
    "    req = urllib.request.Request(url, headers=hdr, data=bytes(data.encode(\"utf-8\")))\n",
    "    req.get_method = lambda: 'POST'\n",
    "    response = urllib.request.urlopen(req)\n",
    "    \n",
    "    # Parse the response and extract content\n",
    "    response_body = response.read()\n",
    "    response_json = json.loads(response_body.decode('utf-8'))\n",
    "    \n",
    "    # Extract and print only the content of the response\n",
    "    response_content = response_json['choices'][0]['message']['content']\n",
    "    print(response_content)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "recommendations_text = response_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255e283e-f8b0-424d-81f4-3448d5a0b6ba",
   "metadata": {},
   "source": [
    "Consumption Drivers Text Length Adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "baf6581b-5cb3-4122-92b3-b95cf0c4bf38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the top 5 drivers that significantly increase the likelihood of weekly consumption of the brand:\n",
      "1. **Self-Purchase**\n",
      "When buyers purchase the product themselves, the probability of weekly consumption increases by 5.1%.\n",
      "2. **Consumption at Home**\n",
      "When the product is consumed at home, the likelihood of weekly consumption rises by 3.7%.\n",
      "3. **Independent Store Availability**\n",
      "The availability of the product at non-chain, independent stores contributes to a 2.0% increase in the likelihood of weekly consumption.\n",
      "4. **Supermarket/Hypermarket/Warehouse Store Availability**\n",
      "The availability of the product at supermarkets, hypermarkets, and warehouse stores can increase the probability of weekly consumption by 1.9%.\n",
      "5. **Immediate Consumption Single-Serve Products (IC-SS)**\n",
      "Providing users with immediate consumption, single-serve options can increase the likelihood of weekly consumption by 1.6%.\n"
     ]
    }
   ],
   "source": [
    "new_prompt = f\"Reduce the number of lines in the following response to only include the top 5 drivers in the numbered list.\\n{consumption_drivers_text}\"\n",
    "\n",
    "# Chat completion request payload\n",
    "irequest = {\n",
    "    \"temperature\": 1,\n",
    "    \"top_p\": 1,\n",
    "    \"max_tokens\": 1000,\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": new_prompt}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Convert request to JSON\n",
    "data = json.dumps(irequest)\n",
    "\n",
    "# Define request URL and headers\n",
    "url = f\"https://apim-emt-aip-prod-01.azure-api.net/openai/deployments/{deployment}/chat/completions?api-version={apiversion}\"\n",
    "hdr = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Ocp-Apim-Subscription-Key': api_key\n",
    "}\n",
    "\n",
    "# Make the request\n",
    "try:\n",
    "    req = urllib.request.Request(url, headers=hdr, data=bytes(data.encode(\"utf-8\")))\n",
    "    req.get_method = lambda: 'POST'\n",
    "    response = urllib.request.urlopen(req)\n",
    "    \n",
    "    # Parse the response and extract content\n",
    "    response_body = response.read()\n",
    "    response_json = json.loads(response_body.decode('utf-8'))\n",
    "    \n",
    "    # Extract and print only the content of the response\n",
    "    response_content = response_json['choices'][0]['message']['content']\n",
    "    cleaned_response = \"\\n\".join(line for line in response_content.splitlines() if line.strip())\n",
    "    print(cleaned_response)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "consumption_drivers_text = cleaned_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb739a9-4a01-4fb4-86d3-6a123c21fa6b",
   "metadata": {},
   "source": [
    "Equity Drivers Text Length Adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c72c07bc-9318-4479-886c-2896a4e94e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 5 drivers that significantly increase the likelihood of weekly consumption of the brand are:\n",
      "1. **Familiarity**\n",
      "When users are familiar with the product, it increases the likelihood of weekly consumption by 11.0%.\n",
      "2. **Affinity**\n",
      "Users who love the brand contribute to an 8.8% increase in the likelihood of weekly consumption.\n",
      "3. **Target Intenders Segment**\n",
      "Targeting potential users can increase weekly consumption likelihood by 8.2%.\n",
      "4. **Brand Preference (First Choice)**\n",
      "Being a consumer's first choice brand can increase the likelihood of weekly consumption by 5.5%.\n",
      "5. **Meeting Needs**\n",
      "If consumers believe the brand meets their needs, it can increase weekly consumption likelihood by 4.0%.\n"
     ]
    }
   ],
   "source": [
    "new_prompt = f\"Reduce the number of lines in the following response to only include the top 5 drivers in the numbered list.\\n{equity_drivers_text}\"\n",
    "\n",
    "# Chat completion request payload\n",
    "irequest = {\n",
    "    \"temperature\": 1,\n",
    "    \"top_p\": 1,\n",
    "    \"max_tokens\": 1000,\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": new_prompt}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Convert request to JSON\n",
    "data = json.dumps(irequest)\n",
    "\n",
    "# Define request URL and headers\n",
    "url = f\"https://apim-emt-aip-prod-01.azure-api.net/openai/deployments/{deployment}/chat/completions?api-version={apiversion}\"\n",
    "hdr = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Ocp-Apim-Subscription-Key': api_key\n",
    "}\n",
    "\n",
    "# Make the request\n",
    "try:\n",
    "    req = urllib.request.Request(url, headers=hdr, data=bytes(data.encode(\"utf-8\")))\n",
    "    req.get_method = lambda: 'POST'\n",
    "    response = urllib.request.urlopen(req)\n",
    "    \n",
    "    # Parse the response and extract content\n",
    "    response_body = response.read()\n",
    "    response_json = json.loads(response_body.decode('utf-8'))\n",
    "    \n",
    "    # Extract and print only the content of the response\n",
    "    response_content = response_json['choices'][0]['message']['content']\n",
    "    cleaned_response = \"\\n\".join(line for line in response_content.splitlines() if line.strip())\n",
    "    print(cleaned_response)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "equity_drivers_text = cleaned_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512d72de-0a6a-4f90-af91-2ee16acc8ceb",
   "metadata": {},
   "source": [
    "Create a string for the Brand + Country Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a39f6df9-c8cf-41a8-988a-be3780355c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_string = country_id + \" - \" + brand_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb556477-cb0e-43d0-af09-7b8a298cf1fe",
   "metadata": {},
   "source": [
    "#### Get the Brand Logo Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da11579a-4683-4797-a089-50ab8e375320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pptx import Presentation\n",
    "from pptx.util import Inches\n",
    "from io import BytesIO\n",
    "\n",
    "def insert_image_from_url(slide, image_url, left, top, width=None, height=None):\n",
    "    \"\"\"Download image from URL and insert into slide at specified position.\"\"\"\n",
    "    response = requests.get(image_url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        # Download the image\n",
    "        image_stream = BytesIO(response.content)\n",
    "\n",
    "        # Add the image to the slide\n",
    "        if width and height:\n",
    "            slide.shapes.add_picture(image_stream, left, top, width, height)\n",
    "        else:\n",
    "            slide.shapes.add_picture(image_stream, left, top)\n",
    "\n",
    "# Loop through slides and shapes to update the text and insert images\n",
    "for slide in prs.slides:\n",
    "    for shape in slide.shapes:\n",
    "        if not shape.has_text_frame:\n",
    "            continue  # Skip non-text shapes\n",
    "        \n",
    "        # Update text in various boxes\n",
    "        if \"recommendations_text\" in shape.text:\n",
    "            update_shape_text_with_bold(shape, recommendations_text, font_size)\n",
    "        \n",
    "        if \"consumption_drivers_text\" in shape.text:\n",
    "            update_shape_text_with_bold(shape, consumption_drivers_text, font_size)\n",
    "        \n",
    "        if \"equity_drivers_text\" in shape.text:\n",
    "            update_shape_text_with_bold(shape, equity_drivers_text, font_size)\n",
    "        \n",
    "        if \"brand_country\" in shape.text:\n",
    "            update_shape_text_with_bold(shape, brand_string, font_size, is_header=True)\n",
    "    \n",
    "    # Insert image into a specific slide (adjust slide number as needed)\n",
    "    # Example URL of an image and its position\n",
    "    image_url = 'https://example.com/path/to/image.jpg'\n",
    "    insert_image_from_url(slide, image_url, margin_right=Inches(.25), margin_top=Inches.25))\n",
    "\n",
    "# Save the updated PowerPoint presentation\n",
    "prs.save(output_path)\n",
    "\n",
    "print(f\"PowerPoint saved as {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2055a4a-e989-495d-a0d0-8c7a1f801ce8",
   "metadata": {},
   "source": [
    "#### Create a PowerPoint Presentation with this information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "23f7dac4-d719-409e-b9df-5a46914945fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PowerPoint saved as C:\\Users\\O52834\\OneDrive - The Coca-Cola Company\\Documents\\BEACH\\W+ Modeling\\Iteration Outputs\\USA_br_0201.pptx\n"
     ]
    }
   ],
   "source": [
    "# Load the template PowerPoint file\n",
    "prs = Presentation(template_path)\n",
    "\n",
    "# Define the desired font sizes (in points)\n",
    "font_size = Pt(11)  # Regular font size\n",
    "font_size_header = Pt(20)  # Header font size\n",
    "\n",
    "def update_shape_text_with_bold(shape, new_text, font_size, is_header=False):\n",
    "    # Clear existing text\n",
    "    text_frame = shape.text_frame\n",
    "    text_frame.clear()\n",
    "\n",
    "    # Find parts of the text that need to be bold\n",
    "    parts = re.split(r\"(\\*\\*.*?\\*\\*)\", new_text)  # Split by the bold markers '**'\n",
    "\n",
    "    # Add a single paragraph to the text frame\n",
    "    p = text_frame.add_paragraph()\n",
    "    \n",
    "    # Add the text in parts, formatting as necessary\n",
    "    for part in parts:\n",
    "        if part.startswith(\"**\") and part.endswith(\"**\"):\n",
    "            # Remove the '**' markers and set the text as bold\n",
    "            bold_text = part[2:-2]\n",
    "            run = p.add_run()\n",
    "            run.text = bold_text\n",
    "            run.font.bold = True\n",
    "        else:\n",
    "            # Non-bold text\n",
    "            run = p.add_run()\n",
    "            run.text = part\n",
    "        \n",
    "        # Set the font size and style\n",
    "        if is_header:\n",
    "            run.font.size = font_size_header\n",
    "        else:\n",
    "            run.font.size = font_size\n",
    "\n",
    "def update_shape_as_numbered_list(shape, text, font_size):\n",
    "    # Clear existing text\n",
    "    text_frame = shape.text_frame\n",
    "    text_frame.clear()\n",
    "\n",
    "    # Split the text into items assuming each item is separated by a newline\n",
    "    items = text.strip().split('\\n')\n",
    "\n",
    "    for i, item in enumerate(items):\n",
    "        # Add a new paragraph for each item\n",
    "        p = text_frame.add_paragraph()\n",
    "        \n",
    "        # Add the number and format it with font size\n",
    "        num_run = p.add_run()\n",
    "        num_run.text = f\"{i + 1}. \"  # Numbering\n",
    "        num_run.font.size = font_size  # Set font size for the number\n",
    "        \n",
    "        # Process the item text for bold formatting\n",
    "        parts = re.split(r\"(\\*\\*.*?\\*\\*)\", item.strip())  # Split by the bold markers '**'\n",
    "        \n",
    "        for part in parts:\n",
    "            if part.startswith(\"**\") and part.endswith(\"**\"):\n",
    "                # Remove the '**' markers and set the text as bold\n",
    "                bold_text = part[2:-2]\n",
    "                run = p.add_run()\n",
    "                run.text = bold_text\n",
    "                run.font.bold = True\n",
    "            else:\n",
    "                # Non-bold text\n",
    "                run = p.add_run()\n",
    "                run.text = part\n",
    "            \n",
    "            # Set the font size for the text\n",
    "            run.font.size = font_size\n",
    "\n",
    "def insert_image_from_url(slide, image_url, left, top, width=None, height=None):\n",
    "    \"\"\"Download image from URL and insert into slide at specified position.\"\"\"\n",
    "    response = requests.get(image_url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        # Download the image\n",
    "        image_stream = BytesIO(response.content)\n",
    "\n",
    "        # Add the image to the slide\n",
    "        if width and height:\n",
    "            slide.shapes.add_picture(image_stream, left, top, width, height)\n",
    "        else:\n",
    "            slide.shapes.add_picture(image_stream, left, top)\n",
    "\n",
    "# Loop through slides and shapes to update the text\n",
    "for slide in prs.slides:\n",
    "    for shape in slide.shapes:\n",
    "        if not shape.has_text_frame:\n",
    "            continue  # Skip non-text shapes\n",
    "        \n",
    "        # Update text in various boxes\n",
    "        if \"recommendations_text\" in shape.text:\n",
    "            update_shape_text_with_bold(shape, recommendations_text, font_size)\n",
    "        \n",
    "        if \"consumption_drivers_text\" in shape.text:\n",
    "            update_shape_text_with_bold(shape, consumption_drivers_text, font_size)\n",
    "        \n",
    "        if \"equity_drivers_text\" in shape.text:\n",
    "            update_shape_text_with_bold(shape, equity_drivers_text, font_size)\n",
    "        \n",
    "        if \"brand_country\" in shape.text:\n",
    "            update_shape_text_with_bold(shape, brand_string, font_size, is_header=True)\n",
    "    \n",
    "    # Insert image into a specific slide (adjust slide number as needed)\n",
    "    # Example URL of an image and its position\n",
    "    image_url = 'https://example.com/path/to/image.jpg'\n",
    "    insert_image_from_url(slide, image_url, margin_right=Inches(.25), margin_top=Inches.25))\n",
    "\n",
    "# Save the updated PowerPoint presentation\n",
    "prs.save(output_path)\n",
    "\n",
    "print(f\"PowerPoint saved as {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d417b1-5224-499a-8291-73d86c4fdf3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
